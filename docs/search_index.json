[["index.html", "The {squidSim} R Package Vignette The {squidSim} R package", " The {squidSim} R Package Vignette Joel Pick 2022-09-22 The {squidSim} R package The {squidSim} R package is designed to simplify data simulation from a highly flexible set of models, including: Correlated and interacting predictor variables Non-Gaussian response variables (Poisson and binomial) Crossed and nested hierarchical structures Random intercepts and slopes Univariate and multivariate data Within level-specific residual variance (DHGLMs) Additive genetic effects (animal models) Phylogenetic effects with different models of evolution Temporal and spatial autocorrelation Missing data (MNAR, MAR and MCAR) Temporal sampling The main idea is that anything you can model using a linear mixed effect model framework (assuming underlying multivariate normality) you can simulate using the {squidSim} package. Why use {squidSim}? For people confident with programming in R, simulating data doesn’t provide a huge challenge. However, to those less confident with programming, or the process of data simulation more generally, starting with simulations can seem like a daunting task. The {squidSim} R package is designed to facilitate that transition, and to focus attention on the data structure and parameters needed for simulation, rather than the programming knowledge. {squidSim} also provides a useful tool for experienced programmers. One problematic aspect of collaborative coding (or reviewing someone else’s code) is that many people have very contrasting programming styles. Another motivation for the {squidSim} package is that it provides a consistent framework for simulations, which can be interpreted by many people rather than having to decipher someone’s personal code. Using the vignette If you are new to using the {squidSim} package, we recommend that you read Sections 1 and 2 to familiarise yourself with the {squidSim} package before moving onto the more advanced topics. The later sections assume an certain level of understanding of how the functions work. The vignette assumes that you have a working knowledge of R, in particular being comfortable using vectors, matrices and lists. Installation The {squidSim} package is currently only available on github: devtools::install_github(&quot;squidgroup/squidSim&quot;) library(squidSim) Issues and bugs It would be great if you could report any suggestions, issues or bugs; here for issues relating to the package, and herefor issues relating to this vignette. It is worth checking to see if anyone else has a similar problem first, and adding comments to their issue, before starting a new one. "],["simulate_population-function.html", "simulate_population function", " simulate_population function The heart of the {squidSim} R package is the simulate_population() function, which we can use to simulate hierarchical, population level data. We provide the function with a set of parameters, a hierarchical data structure (if we are simulating hierarchical data), and various other optional arguments, which are listed below. The simulate_population() function simulates predictors at each hierarchical level, using provided mean and variance-covariance (vcov) parameters, from a multivariate normal distribution. These predictors are then scaled by the beta parameters, and added together to create the response. The arguments that can be provided to the simulate_population() function (along with their defaults) are: simulate_population( data_structure, n, parameters, n_response=1, response_names, family=&quot;gaussian&quot;, link=&quot;identity&quot;, model, known_predictors, pedigree, pedigree_type, phylogeny, phylogeny_type, cov_str, sample_type, sample_param, n_pop=1 ) Each of these will be covered in more detail in the following sections. Briefly, n and data_structure refer to the size and structure of the data being simulated - data_structure is covered in more detail in Section 2. parameters is a list of parameters to be used in the simulation and is described in detail in Section 1. n_response refers the number of response variable to be simulated and is covered in detail in the section on multivariate models (Section 3). response_names controls what the simulated response variables are named, and is described in Sections 1 and 3. family and link refer to simulating non Gaussian response variables and are covered in Section 1.6. model allows for the specification of more complex models and is covered in Section 1.7. known_predictors allows for existing data to be incorporated into the simulations and is covered in 1.5. pedigree and pedigree_type relate to simulating genetic effects and are covered in Section 4, phylogeny and phylogeny_type, relate to simulating phylogenetic effects and are covered in Section 5 and cov_str relates to simulating a general covariance structure and is covered in multiple sections, including 4, 5, 6.3 and 6.4. sample_type and sample_param relate to different sampling methods and are covered in Section 7 n_pop relates to the number of populations, or datasets, that you want to simulate for each parameter set. This is covered in Section 1.8. "],["vignette-notation.html", "Vignette Notation", " Vignette Notation We try to use a consistent notation in equations throughout the manuscript, which we try to explain as we go. For the sake of clarity we have outlined everything here. General rules Small letters (e.g. \\(x\\)) denote scalars Bold, small letters (e.g. \\(\\boldsymbol{x}\\)) denote vectors Capital letters (e.g. \\(X\\)) denote matrices Letter/Symbol Usage \\(\\sigma\\) standard deviation \\(\\Sigma\\) covariance matrix \\(\\sigma_{x_1x_2}\\) covariance between variables x1 and x2 \\(\\mu\\) mean \\(\\epsilon\\) residual \\(\\beta\\) slope \\(x\\) predictor variable \\(y\\) response variable Notation for a linear mixed model There are several ways to write out an equation for a linear model. First we can write out all the different variables: \\(y_i = \\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\beta_3 x_{3,i} + \\epsilon_i\\) where each observation (denoted by the index \\(i\\)) of our response variable (\\(y_i\\)) is the sum of an intercept (\\(\\beta_0\\); value of the response when the predictor variables are all 0), the associated value of our predictor variables (\\(x_{1i}\\), \\(x_{2i}\\), \\(x_{3i}\\); which also vary at the level of the observation), each with a certain magnitude and direction of their effect (effect size or slope; \\(\\beta_1\\) etc), and some unexplained, residual variation (\\(\\epsilon_i\\)). We can also write this in matrix notation: \\(\\boldsymbol{y} = X\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\) where \\(X\\) is a matrix of predictors and \\(\\boldsymbol{\\beta}\\) is a (column) vector of slopes/effect sizes. This matrix notation is a bit more compact and relates most easily the structure of the simulate_population() function. However it becomes more complex when we have things varying at different levels, as we have to start getting design matrices for the random effects involved e.g. \\(\\boldsymbol{y} = X\\boldsymbol{\\beta} + Z\\boldsymbol{u} + \\boldsymbol{\\epsilon}\\) which we would rather avoid here as it has little relation to the squidSim code. We can therefore combine the index and matrix notation. This is maybe a little more complex, but it’s compact and flexible and relates well to the simulate_population() function. \\(y_{i} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta} + \\epsilon_{i}\\) where \\(\\boldsymbol{x}_{i}\\) is the \\(i\\)th row of \\(X\\). I have deliberately separated the intercept (\\(\\beta_0\\)) out here, for the purpose of comparing with the structure of simulate_population(). Then for models that have predictors vary at different levels we can have \\(y_{ij} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta}_x + \\boldsymbol{u}_j \\boldsymbol{\\beta}_u + \\epsilon_{ij}\\) Instead of having predictors at different levels, we might have ‘random effects’ \\(y_{ij} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta}_x + u_j + \\epsilon_{ij}\\) at multiple levels \\(y_{ijk} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta}_x + u_j + w_k + \\epsilon_{ijk}\\) Distributions We can write distribution equations as: \\(x_{1i} \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) or \\(\\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x)\\) Interactions / Random regression \\(y_{ij} = \\beta_0 + \\beta_1x_{i} + u_{1j} + x_{i}u_{2j} + \\epsilon_{ij}\\) \\(x_{i} \\sim \\mathcal{N}(\\mu_x, \\sigma^2_x)\\) \\(\\boldsymbol{u}_i \\sim \\mathcal{N}(0, \\Sigma_u)\\) \\(\\epsilon_{i} \\sim \\mathcal{N}(0, \\sigma^2_{\\epsilon})\\) Multi-response \\(\\boldsymbol{y}_{ij} = \\boldsymbol{\\beta}_0 + \\boldsymbol{x}_{i} B_x + \\boldsymbol{u}_j + \\boldsymbol{\\epsilon}_{ij}\\) \\(\\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x)\\) \\(\\boldsymbol{u}_i \\sim \\mathcal{N}(0, \\Sigma_u)\\) \\(\\boldsymbol{\\epsilon}_{i} \\sim \\mathcal{N}(0, \\Sigma_{\\epsilon})\\) where \\(\\boldsymbol{\\beta}_0\\) is a vector of intercepts of length q (number of responses) \\(B\\) is a \\(p*q\\) (p - number of predictors) matrix of \\(\\beta\\)s "],["1-linearmod.html", "1 Simulating from linear models", " 1 Simulating from linear models In this section, we will look at simulating data simple data from linear models, to familiarise ourselves with how {squidSim} works. "],["1.1-simple-linear-model.html", "1.1 Simple Linear Model", " 1.1 Simple Linear Model We will start simulating data without any hierarchical structure, i.e. everything varies at the level of the observation. Let’s imagine a situation where body mass is affected by some environmental variables - temperature, rainfall and wind. We can write this out in the form of a linear model: \\[ y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + \\epsilon_i \\] where each observation (denoted by the index \\(i\\)) of our response variable (\\(y_i\\)) is the sum of an intercept (\\(\\beta_0\\); value of the response when the predictor variables are all 0), the associated value of our predictor variables (\\(x_{1i}\\), \\(x_{2i}\\), \\(x_{3i}\\); which also vary at the level of the observation), each with a certain magnitude and direction of their effect (effect size or slope; \\(\\beta_1\\) etc), and some unexplained, residual variation (\\(\\epsilon_i\\)). We can write this in more compact notation, \\[ y_{i} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta} + \\epsilon_{i} \\] where \\(\\boldsymbol{x}_{i}\\) is a (row) vector of \\(x_{1i}\\), \\(x_{2i}\\) \\(x_{3i}\\) etc, or equivalently row \\(i\\) in the matrix of predictors \\(X\\), \\[ \\boldsymbol{x}_{i} = \\begin{bmatrix} x_{1i} &amp; x_{2i} &amp; x_{3i} \\end{bmatrix} \\] and \\(\\boldsymbol{\\beta}\\) is a (column) vector of slopes/effect sizes \\[ \\boldsymbol{\\beta} = \\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} \\] We will use this notation in the vignette, as it is a bit more compact, relates most easily the structure of the simulate_population() function, and can incorporate the flexibility needed for the different model structures. If we want to simulate from this model, we can assume that these predictor variables are multivariate normally distributed, with given means (\\(\\mu\\)) and a covariance structure (\\(\\Sigma_x\\)), and the residuals are normally distributed with a given variance (\\(\\sigma^2_\\epsilon\\)) \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] where \\[ \\boldsymbol{\\mu}_x = \\begin{bmatrix} \\mu_{x_1} \\\\ \\mu_{x_2} \\\\ \\mu_{x_3} \\end{bmatrix} , \\Sigma_x = \\begin{bmatrix} \\sigma^2_{x_1} &amp; \\sigma_{x_1x_2} &amp; \\sigma_{x_1x_3}\\\\ \\sigma_{x_1x_2} &amp; \\sigma^2_{x_2} &amp; \\sigma_{x_2x_3}\\\\ \\sigma_{x_1x_3} &amp; \\sigma_{x_2x_3} &amp; \\sigma^2_{x_3} \\end{bmatrix} \\] The key to simulating data using the squidSim package is correctly specifying the parameters (from the equations above that would be \\(\\beta_0\\), \\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\mu}_x\\), \\(\\Sigma_x\\), \\(\\sigma^2_\\epsilon\\)). These parameters are given to the simulate_population function as a nested list. Within the main parameter list, there are named lists corresponding to different hierarchical levels, containing the parameters for the predictors at that level - here we are just focussing on the observation level (see Section 2 for examples with hierarchical structure). Parameters for the residual must be specified, all other levels are optional. In addition to the named lists relating to hierarchical levels, a vector for intercepts and a list for interactions can be added. Intercepts are demonstrated in the examples below, and interactions in Section 1.3. Many of the components in the parameter list don’t need to be specified and default values will be created. Let’s simulate from the above model. First we can specify a sample size or data_structure. As we don’t have any hierarchical data structure yet (see Section 2), we have to specify the sample size with the n argument to the simulate_population function (e.g. 2000). simulate_population( n=2000, ... ) We can also give the response (\\(y\\)) variable a name, body_mass (this is not needed, and defaults to y if not specified). simulate_population( n=2000, response_name = &quot;body_mass&quot;, ... ) We then need to add in our parameter list: simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters = list( ... ) ) To fill in our parameter list, lets think about our model \\[ y_{i} = \\color{red}{\\beta_0}+ \\color{blue}{\\boldsymbol{x}_{i} \\boldsymbol{\\beta}} + \\color{orange}{\\epsilon_{i}} \\] \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] or in words: intercept + observation level predictors + residual These names correspond to names in our parameter list. To simulate our environmental predictors that vary at the level of the observation, we can use the observation slot in the parameter list, as well as specifying an intercept and residual variance in the intercept and residual slots, respectively. The global intercept (\\(\\beta_0\\)) is given by specifying an intercept vector in the parameter list e.g. intercept=10 For both observation and residual we create a list containing the respective parameters. For the observation list, we can specify the names of these variables as a vector (these can be anything - I like giving things actual names, but could also be x1, x2 and x3) and, in the simplest case, the \\(\\beta\\) values as a vector. observation = list( names = c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), beta = c(0.5,-0.3, 0.4) ) By default, these predictors are simulated as i.i.d. unit normals (mean=0, var=1, cov=0), so \\[ \\boldsymbol{\\mu}_x = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix} , \\Sigma_x = \\begin{bmatrix} 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] Note that the order of the names and betas has to match. We can then specify the residual variance, here as 0.8 (but can be anything). vcov refers to the variance-covariance matrix, which for the residuals is only a single variance until we have multiple response variables (Section 3). residual = list( vcov = 0.8 ) We can then put this all together: squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters = list( intercept=10, observation = list( names = c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), beta = c(0.5,-0.3, 0.4) ), residual = list( vcov = 0.8 ) ) ) Let’s compare the code back to the model: \\[ y_{i} = \\color{red}{\\beta_0}+ \\color{blue}{\\boldsymbol{x}_{i} \\boldsymbol{\\beta}} + \\color{orange}{\\epsilon_{i}} \\] \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] squid_data &nbsp;&nbsp;n=2000,&nbsp;&nbsp;response_name = \"body_mass\",&nbsp;&nbsp;parameters = list(&nbsp;&nbsp;&nbsp;&nbsp;intercept=10,&nbsp;&nbsp;&nbsp;&nbsp;observation = list(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;names = c(\"temperature\",\"rainfall\", \"wind\"),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;beta = c(0.5,-0.3, 0.4) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;),&nbsp;&nbsp;&nbsp;&nbsp;residual = list(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vcov = 0.8&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;)) This generates a squid object, which when run returns a friendly message: squid_data ## Data simulated using squid ## ## /\\ ## / \\ ## / /\\ \\ ## \\/ \\/ ## / \\ ## | | ## | | ## 0 | | 0 ## / \\____/ \\ ## { __/( )\\__ } ## \\___/__\\_\\/_/__\\___/ ## / / / / \\ \\ \\ \\ ## / / / { } \\ \\ \\ ## { { / \\ / \\ } } ## } \\ 0 0 / { ## 0_/ { \\_0 0_/ } \\_0 ## \\ / ## } { ## / \\ ## 0 0 and contains all our simulation parameters as well as the simulated data. At this point we want to be able to access the simulated data. There are then some further functions which we can use to access the data and simulation parameters. We can extract the simulated data using get_population_data() The generated response is returned, along with simulated predictors and the data structure (not relevant here). data &lt;- get_population_data(squid_data) head(data) ## body_mass temperature rainfall wind residual squid_pop ## 1 7.737309 -0.2306292 0.3793662 -1.621588 -1.3849315 1 ## 2 7.842569 -0.8841745 -0.7383195 -0.787488 -1.6218444 1 ## 3 12.069817 0.9715341 0.5082774 1.591818 1.0998057 1 ## 4 10.693063 0.1834473 -0.1029349 -0.544928 0.7884305 1 ## 5 11.686525 1.6707325 2.0234161 1.895537 0.6999690 1 ## 6 9.000434 -2.2209488 0.8709182 1.206219 -0.1103037 1 Later on we will explore how to simulate data for multiple populations with the same parameters (Section 1.8). squid_pop is an identifier for the population number, but is not relevant here. We can plot what we have simulated: library(scales) par(mfrow=c(1,3)) plot(body_mass ~ temperature + rainfall + wind, data, pch=19, cex=0.5, col=alpha(1,0.5)) and run a linear model to check that we get back the betas that we simulated: coef(lm(body_mass ~ temperature + rainfall + wind,data)) ## (Intercept) temperature rainfall wind ## 9.9650211 0.5232290 -0.3234344 0.3897914 We can also check the means and variances of the predictors predictors &lt;- data[,c(&quot;temperature&quot;,&quot;rainfall&quot;,&quot;wind&quot;)] colMeans(predictors) ## temperature rainfall wind ## 0.012155934 0.004824320 -0.004908366 cov(predictors) ## temperature rainfall wind ## temperature 0.994203543 0.001712154 0.01044419 ## rainfall 0.001712154 1.050196516 -0.01773955 ## wind 0.010444186 -0.017739548 1.04555048 Its worth noting that these values are not exactly what we simulated. That is to be expected - simulation involves randomly generating data, which means that here will be stochasticity in the simulated sample, and in our estimates of the underlying parameters. 1.1.1 Adding more information about the predictors We can also specify the predictors as having different means and variances. In the observation list, mean and vcov specify the means and covariance matrix of the predictors. If the predictors were uncorrelated, we can just specify the variances as a vector (the diagonal elements of the covariance matrix), and the function assumes the covariances are 0 (see section 1.2 for correlated predictors). Below we have three predictors, temperature, rainfall and wind, with means 10, 1 and 20 respectively, variances 1, 0.1 and 2, respectively, and betas 0.5,-3 and 0.4, a residual variance 0.8 and a global intercept of 10: \\[ y_{i} = beta_0+ \\boldsymbol{x}_{i} \\boldsymbol{\\beta} + \\epsilon_{i} \\] \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] \\[ \\color{red}{\\\\beta_0=10} , \\color{blue}{\\boldsymbol{\\mu}_x = \\begin{bmatrix} 10 \\\\ 1 \\\\ 20 \\end{bmatrix}} , \\color{CornflowerBlue}{\\Sigma_x = \\begin{bmatrix} 1 &amp; 0 &amp; 0\\\\ 0 &amp; 0.1 &amp; 0\\\\ 0 &amp; 0 &amp; 2 \\end{bmatrix}} , \\color{purple}{\\boldsymbol{\\beta} = \\begin{bmatrix} 0.5 \\\\ -3 \\\\ 0.4 \\end{bmatrix}} , \\color{orange}{\\sigma^2_\\epsilon=0.8} \\] squid_data &nbsp;&nbsp;n=2000,&nbsp;&nbsp;response_name = \"body_mass\",&nbsp;&nbsp;parameters=list(&nbsp;&nbsp;&nbsp;&nbsp;intercept = 10,&nbsp;&nbsp;&nbsp;&nbsp;observation=list(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;names = c(\"temperature\",\"rainfall\", \"wind\"),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mean = c(10,1,20),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vcov = c(1,0.1,2),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;beta = c(0.5,-3,0.4)&nbsp;&nbsp;&nbsp;&nbsp;),&nbsp;&nbsp;&nbsp;&nbsp;residual=list(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vcov = 0.8&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;)) data &lt;- get_population_data(squid_data) coef(lm(body_mass ~ temperature + rainfall + wind, data)) ## (Intercept) temperature rainfall wind ## 10.1958870 0.5141206 -3.1041906 0.3899635 library(scales) par(mfrow=c(1,3)) plot(body_mass ~ temperature + rainfall + wind, data, pch=19, cex=0.5, col=alpha(1,0.5)) Again, we can check that the means and variances of the predictors are being simulated as we think they should be predictors &lt;- data[,c(&quot;temperature&quot;,&quot;rainfall&quot;,&quot;wind&quot;)] colMeans(predictors) ## temperature rainfall wind ## 10.0376901 0.9913311 19.9980632 cov(predictors) ## temperature rainfall wind ## temperature 1.000964250 0.007210948 0.01717880 ## rainfall 0.007210948 0.098615850 0.01599828 ## wind 0.017178798 0.015998285 2.06563781 It can be complicated to keep up with how these different values combine to give the mean and variance of the response. To help with this, the simulated_variance() function calculates the expected mean and variance of the response variable, as well as breaking down the contribution of different predictors and hierarchical levels to the these. simulated_variance(squid_data) ## Contribution of the simulated predictors to the mean and variance in the response ## ## Simulated Mean: 20 ## Simulated Variance: 2.27 ## ## Contribution of different hierarchical levels to grand mean and variance: ## mean var ## intercept 10 0.00 ## observation 10 1.47 ## residual 0 0.80 ## ## ## Contribution of different predictors to grand mean and variance: ## mean var ## intercept 10 0.00 ## temperature 5 0.25 ## rainfall -3 0.90 ## wind 8 0.32 ## residual 0 0.80 "],["1.2-corpred.html", "1.2 Correlated predictors", " 1.2 Correlated predictors We can also simulate correlations between these predictors, as vcov specifies the variance/covariance matrix of the predictors. squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( intercept=10, observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), mean = c(10,1 ,20), vcov =matrix(c( 1, 0, 1, 0,0.1,0, 1, 0, 2 ), nrow=3 ,ncol=3,byrow=TRUE), beta =c(0.5,-3,0.4) ), residual=list( vcov=1 ) ) ) data &lt;- get_population_data(squid_data) library(scales) par(mfrow=c(1,3)) plot(body_mass ~ temperature + rainfall + wind, data, pch=19, cex=0.5, col=alpha(1,0.5)) coef(lm(body_mass ~ temperature + rainfall + wind, data)) ## (Intercept) temperature rainfall wind ## 9.7745865 0.4847876 -2.9889811 0.4172907 div.blue { background-color:#fcba03; border-radius: 5px; padding: 20px;} Matrices in R To code a matrix in R we use the matrix function (see ?matrix). This takes a vector of values, and arranges then in a matrix, with dimensions specified with nrow and ncol. By default it fills the matrix by column, which can be changed by specifying byrow=TRUE. For big matrices this can be petty annoying. TheTri2M() function from the package MCMCglmm allows you to just give the lower or upper half of the matrix, and it will fill the rest out for you. For example, we can make a correlation matrix using: Tri2M(c(1,0.5,1,0.3,0.2,1), lower.tri = FALSE, diag=TRUE) ## [,1] [,2] [,3] ## [1,] 1.0 0.5 0.3 ## [2,] 0.5 1.0 0.2 ## [3,] 0.3 0.2 1.0 Instead of specifying a variance-covariance matrix (vcov), we can also specify a variance-correlation matrix (variance on the diagonals and correlations on the off-diagonals), using vcorr squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( intercept=10, observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), mean = c(10,1,20), vcorr =matrix(c( 1, -0.2, 0.5, -0.2, 0.1, 0.3, 0.5, 0.3, 2 ), nrow=3 ,ncol=3,byrow=TRUE), beta =c(0.5,-3,0.4) ), residual=list( vcov=1 ) ) ) data &lt;- get_population_data(squid_data) cor(data[,c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;)]) ## temperature rainfall wind ## temperature 1.0000000 -0.1812635 0.5176010 ## rainfall -0.1812635 1.0000000 0.2617843 ## wind 0.5176010 0.2617843 1.0000000 Through simulating correlated predictors, we can also simulate more interesting phenomena. For example, we may want to simulate the effect of a correlated missing predictor. Here, rain and wind, but not temperature, affect adult body mass, but only temperature and rainfall are measured: squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( intercept=10, observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), mean = c(10,1 ,20), vcov =matrix(c( 1, 0, 1, 0,0.1,0, 1, 0, 2 ), nrow=3 ,ncol=3,byrow=TRUE), beta =c(0.5,-3,0.4) ), residual=list( vcov=1 ) ) ) data &lt;- get_population_data(squid_data) library(scales) par(mfrow=c(1,3)) plot(body_mass ~ temperature + rainfall + wind, data, pch=19, cex=0.5, col=alpha(1,0.5)) coef(lm(body_mass ~ temperature + rainfall, data)) ## (Intercept) temperature rainfall ## 13.8936511 0.9148843 -3.0592937 coef(lm(body_mass ~ temperature + rainfall + wind, data)) ## (Intercept) temperature rainfall wind ## 10.2631334 0.5509808 -3.0467600 0.3633353 We can also use this to induce measurement error in a predictor - we can simulate the true variable with a certain affect on the response, and another correlated variable - the measured variable - with no direct effect on the response. The correlation between these two variables represents the measurement error (the repeatability of the variable is the correlation squared). "],["1.3-interactions.html", "1.3 Interactions and non-linear effects", " 1.3 Interactions and non-linear effects 1.3.1 Interactions \\[ y_i = \\beta_0 + \\beta_1 * x_{1,i} + \\beta_2 * x_{2,i} + \\beta_3 * x_{1,i}* x_{2,i} + \\epsilon_i \\] We can specify the interaction between two predictors by adding an interactions list to the parameters list. Interactions can then be specified between two named variables using “:”. Interactions can be between predictors at the same or different hierarchical level. squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;), beta = c(0.5,0.3) ), residual=list( vcov=0.3 ), interactions=list( names=c(&quot;temperature:rainfall&quot;), beta = c(-0.1) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## body_mass temperature rainfall residual temperature:rainfall squid_pop ## 1 0.3684694 1.933232214 0.19203892 -0.61863284 0.3712558292 1 ## 2 -0.4730299 0.081011530 -1.32092129 -0.12796029 -0.1070098551 1 ## 3 -1.1576776 0.088942791 -0.70727428 -0.99625744 -0.0629069479 1 ## 4 0.1311283 0.004136626 -0.08379699 0.15416441 -0.0003466369 1 ## 5 0.1344398 0.296427406 -0.27937107 0.06175613 -0.0828132420 1 ## 6 -1.4594139 0.555758164 -1.15559295 -1.45483810 -0.6422302156 1 coef(lm(body_mass ~ temperature * rainfall, data)) ## (Intercept) temperature rainfall ## 0.01175390 0.50865026 0.33617972 ## temperature:rainfall ## -0.09533579 1.3.2 Non-linear effects Polynomial (quadratic, cubic, etc) functions are essentially interactions with the same predictor. They can therefore be specified in the same way: squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( observation=list( names=c(&quot;temperature&quot;), beta = c(0.5) ), interactions=list( names=c(&quot;temperature:temperature&quot;), beta = c(-0.3) ), residual=list( vcov=0.3 ) ) ) data &lt;- get_population_data(squid_data) plot(body_mass ~ temperature, data, pch=19, cex=0.5, col=alpha(1,0.5)) coef(lm(body_mass ~ temperature + I(temperature^2), data)) ## (Intercept) temperature I(temperature^2) ## -0.002908256 0.516327302 -0.291477043 "],["1.4-transformations.html", "1.4 Transformations", " 1.4 Transformations We may want to simulate predictors that are not normally distributed. Although the underlying simulation procedure assumes multivariate normality, the predictors can be transformed, before they are scaled by the beta values. To do this we can provide the transformation function to the functions option of a given parameter list, as a character vector. The given function needs to be a known function in R. The below code will exponentiate rainfall (using the exp function), before it is scaled by its beta (here 2). squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;), functions=c(NA,&quot;exp&quot;), beta = c(0.5,0.3) ), residual=list( vcov=0.3 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## body_mass temperature rainfall residual squid_pop ## 1 0.8808384 0.9661316 1.7834867 -0.1372734 1 ## 2 0.2263617 -0.3593466 1.8415211 -0.1464213 1 ## 3 0.3550851 1.5984683 0.2318093 -0.5136918 1 ## 4 1.4382651 -1.5338100 4.4990114 0.8554666 1 ## 5 0.6630719 2.1241124 0.9072182 -0.6711498 1 ## 6 0.6877911 -0.9466144 0.9671257 0.8709606 1 hist(data$rainfall, breaks=100) If a covariance between variables is specified, this covariance is on the untransformed (Gaussian) scale (as the variables are simulated as multivariate normal), NOT on the transformed scale, so care should be taken with this. For example: squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;), vcov=matrix(c(1,0.7,0.7,1), nrow=2,byrow=TRUE), functions=c(NA,&quot;exp&quot;), beta = c(0.5,0.3) ), residual=list( vcov=0.3 ) ) ) data &lt;- get_population_data(squid_data) cov(data$temperature,data$rainfall) ## [1] 1.132242 cov(data$temperature,log(data$rainfall)) ## [1] 0.6947967 The simulate covariance can be recovered on the back-transformed predictor. The simulated_variance() function will also no longer be accurate, as the calculations are based on variables on the untransformed scale. "],["1.5-knownpreds.html", "1.5 Known Predictors", " 1.5 Known Predictors We might have the situation where we don’t want to simulate a predictor, rather use existing data to simulate a response variable from. This has the advantage that any quirks of existing data (like a strange distribution) can be maintained. These predictors can be fed into the simulate_population() function, using the known_predictors argument. This argument takes a list, with one item, called predictors, a matrix or dataframe of predictors and one item called beta, a vector with the beta values for the respective predictors. Importantly, the predictors have to be the same length as number of observations in the simulated data. We can demonstrate this using the blue tit data set that comes with the MCMCglmm package. library(MCMCglmm) data(BTdata) head(BTdata) ## tarsus back animal dam fosternest hatchdate sex ## 1 -1.89229718 1.1464212 R187142 R187557 F2102 -0.6874021 Fem ## 2 1.13610981 -0.7596521 R187154 R187559 F1902 -0.6874021 Male ## 3 0.98468946 0.1449373 R187341 R187568 A602 -0.4279814 Male ## 4 0.37900806 0.2555847 R046169 R187518 A1302 -1.4656641 Male ## 5 -0.07525299 -0.3006992 R046161 R187528 A2602 -1.4656641 Fem ## 6 -1.13519543 1.5577219 R187409 R187945 C2302 0.3502805 Fem We can see that in this dataset there are several continuous predictors. Here we will use “hatchdate” and “tarsus”. squid_data &lt;- simulate_population( n = nrow(BTdata), response_name = &quot;body_mass&quot;, parameters = list( observation =list( names = c(&quot;temperature&quot;,&quot;rainfall&quot;), beta = c(0.5,0.3) ), residual = list( vcov = 0.3 ) ), known_predictors = list( predictors = BTdata[,c(&quot;hatchdate&quot;,&quot;tarsus&quot;)], beta = c(1,2)) ) data &lt;- get_population_data(squid_data) head(data) ## body_mass temperature rainfall residual hatchdate tarsus ## 1 -4.286821 0.5290832 0.375800507 -0.192105859 -0.6874021 -1.89229718 ## 2 1.858944 0.3625056 0.002274996 0.092191340 -0.6874021 1.13610981 ## 3 1.638961 -0.1032856 0.492434356 0.001475751 -0.4279814 0.98468946 ## 4 -1.182909 0.3381428 1.479198475 -1.088091557 -1.4656641 0.37900806 ## 5 -3.318436 -2.4582996 -0.693746732 -0.264992183 -1.4656641 -0.07525299 ## 6 -1.858113 1.6906011 -0.309655352 -0.690406667 0.3502805 -1.13519543 ## squid_pop ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 plot(body_mass~hatchdate,data) "],["1.6-nonGaussian.html", "1.6 Non-Gaussian phenotypes", " 1.6 Non-Gaussian phenotypes To simulate non-Gaussian data, we can specify a link function and a family as arguments to the simulate_population function. Underneath the predictors are being simulated as multivariate normal (on the latent scale), and then the resulting phenotype is transformed (onto the expected scale) and then binomial or Poisson sampling is applied (the observed scale). Here is an example to simulate POisson distributed data: \\[ y_i \\sim Poisson(\\hat{y_i}) \\] \\[ \\hat{y_i} = exp( \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta} + \\epsilon_i ) \\] \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\epsilon_1 \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] The only change in the code that is need is the addition of the link and family arguments. squid_data &lt;- simulate_population( parameters = list( observation = list( names = c(&quot;temperature&quot;,&quot;rainfall&quot;), beta = c(0.2,0.1) ), residual = list( mean = 1.75, vcov = 0.2 ) ), n = 2000, family = &quot;poisson&quot;, link = &quot;log&quot; ) data &lt;- get_population_data(squid_data) head(data) ## y temperature rainfall residual squid_pop ## 1 0 0.2490819 0.18108147 0.8249614 1 ## 2 3 -0.3059614 -0.01854387 1.0974162 1 ## 3 3 -1.9080617 -0.10657783 1.4348215 1 ## 4 5 -0.3827834 -0.63354609 2.0413375 1 ## 5 5 2.1639215 0.02263793 0.8399427 1 ## 6 4 -0.2962397 -0.14766836 1.6809449 1 plot(table(data$y), ylab=&quot;Frequency&quot;, xlab=&quot;z&quot;) glm(y ~ temperature + rainfall, data, family=&quot;poisson&quot;) ## ## Call: glm(formula = y ~ temperature + rainfall, family = &quot;poisson&quot;, ## data = data) ## ## Coefficients: ## (Intercept) temperature rainfall ## 1.8545 0.1857 0.1124 ## ## Degrees of Freedom: 1999 Total (i.e. Null); 1997 Residual ## Null Deviance: 5169 ## Residual Deviance: 4537 AIC: 11550 Available families are ‘gaussian’, ‘poisson’ or ‘binomial’ and link functions ‘identity’, ‘log’, ‘inverse’, ‘sqrt’, ‘logit’, ‘probit’. "],["1.7-modeleq.html", "1.7 Model equations", " 1.7 Model equations In all the examples so far, the predictors are simulated, scaled by their respective beta value, and then added together. We may want to prevent some of this behaviour or add in additional parameters, interactions or general complexity. In isolation, the functionality outlined here might seem a bit redundant, but it becomes useful for more complex models. To introduce this increased complexity, we can specify a model formula. This explicitly tells the simulate_population function how to put the simulated predictors together to form the response variable. We can first demonstrate this with a simple linear model. squid_data &lt;- simulate_population( parameters=list( observation= list( names = c(&quot;temperature&quot;, &quot;rainfall&quot;), beta =c(0.5,0.3) ), residual = list( names=&quot;residual&quot;, vcov=1 ) ), n=2000, model = &quot;y = temperature + rainfall + residual&quot; ) data &lt;- get_population_data(squid_data) coef(lm(y ~ temperature + rainfall, data)) ## (Intercept) temperature rainfall ## 0.004605396 0.506914670 0.288952532 In the formula, we write out how the variables are added up. Everything that you want exported needs to be defined and named (e.g. y=...). By default they are all scaled by their beta values before this happens. Sometimes it is useful to prevent this (i.e. multiply two traits together without them being scaled by their respective beta) and we can do this by using I(). squid_data &lt;- simulate_population( parameters=list( observation= list( names = c(&quot;temperature&quot;, &quot;rainfall&quot;), beta =c(0.5,0.3) ), residual = list( names=&quot;residual&quot;, vcov=1 ) ), n=2000, model = &quot;y = temperature + I(rainfall) + residual&quot; ) data &lt;- get_population_data(squid_data) coef(lm(y ~ temperature + rainfall, data)) ## (Intercept) temperature rainfall ## -0.004985291 0.495841550 0.960772034 We can also add extra parameters to the parameter list, which we can call from within the function. In combination with I() we can then customise the model formula a bit squid_data &lt;- simulate_population( parameters=list( observation= list( names = c(&quot;temperature&quot;, &quot;rainfall&quot;), beta =c(0.5,0.3), extra_beta = 0.1 ), residual = list( names=&quot;residual&quot;, vcov=1 ) ), n=2000, model = &quot;y = temperature + extra_beta*I(rainfall) + residual&quot; ) data &lt;- get_population_data(squid_data) coef(lm(y ~ temperature + rainfall, data)) ## (Intercept) temperature rainfall ## -0.000221756 0.481460783 0.085752465 Finally, we can use [] to index the levels of the random effects within the formula… "],["1.8-npop.html", "1.8 Simulating multiple populations", " 1.8 Simulating multiple populations We can use the simulate_population() function to generate multiple datasets (populations) form the same set of parameters (world). To do this we can specify the n_pop argument in simulate_population(). This defaults to 1. squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( intercept=10, observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), beta =c(0.5,-0.3,0.4) ), residual=list( vcov=0.8 ) ), n_pop=5 ) By default get_population_data returns a data.frame, where the squid_pop column indicates the population data &lt;- get_population_data(squid_data) head(data) ## body_mass temperature rainfall wind residual squid_pop ## 1 9.963488 -0.87042429 0.08123816 -1.46160423 1.00771338 1 ## 2 11.679887 0.54596251 -1.35020676 0.44824010 0.82254729 1 ## 3 10.205083 0.05409334 -0.59114054 0.30053533 -0.11952024 1 ## 4 9.957851 -1.73773422 -0.62630133 -0.38115588 0.79129050 1 ## 5 10.547339 1.61947126 0.76155388 -0.05519906 -0.01185064 1 ## 6 10.196599 0.68431346 0.65455707 -2.19404168 0.92842638 1 tail(data) ## body_mass temperature rainfall wind residual squid_pop ## 9995 8.086665 -0.6214712 -0.8064454 -0.54186069 -1.6277892272 5 ## 9996 11.521081 0.2075812 -2.0356218 -0.01890323 0.8141651756 5 ## 9997 11.384367 -0.2871820 -1.1694008 0.59354828 0.9397186387 5 ## 9998 11.682527 -0.1509205 -0.9174626 -0.46858243 1.6701819257 5 ## 9999 9.570990 -1.4052158 -1.7697390 -0.97793190 0.1338485092 5 ## 10000 9.421060 -1.1131408 -1.4915844 -1.17264236 -0.0007877935 5 It can also be output as a list, which might be more useful for processing many iterations of a simulation. data &lt;- get_population_data(squid_data, list=TRUE) length(data) ## [1] 5 "],["1.9-parameter-list-summary.html", "1.9 Parameter list summary", " 1.9 Parameter list summary The parameters list contains one (or more) list for each hierarchical level that you want to simulate at. A residual list is always need, specifying variances/covariances for the residual. Additionally, the parameter list can also be provided with an intercept vector and interactions list. The simplest paramter list will look something like this: parameters=list( residual=list( vcov=... ) ) We can add more complexity by adding an intercept (if not specified, is assumed to be 0): parameters=list( intercept=c(...), residual=list( vcov=... ) ) and then simulate variables that vary at the observation level: parameters=list( intercept=c(...), observation=list( beta = ... ), residual=list( vcov = ... ) ) as well as variables that vary at the other levels, for example at the level of the individual: parameters=list( intercept=c(...), individual=list( names = c(...), beta = ... ), observation=list( names = c(...), beta = ... ), residual=list( vcov = ... ) ) Finally we can add in interactions: parameters=list( intercept=c(...), individual=list( names = c(...), beta = ... ), observation=list( names = c(...), beta = ... ), interactions=list( names = c(...), beta = ... ), residual=list( vcov = ... ) ) For each item in the parameter list (excluding intercept, interactions, and residual), the following can be specified: names Vector containing the names of predictors from this list that will be output. This doesn’t not have to be specified, unless the predictors at this level are included in interactions. By default, the names will be the name of the list (e.g. ‘individual’ in the example above), appended with _effect and a sequential number if there are multiple predictors. group Character string relates the level of variation back to the data_structure. Does not have to be specified and by default is the name of the list. mean Vector of means for the predictor variables. Defaults to 0. vcov Either a vector of variances, or a variance-covariance matrix, for the predictor variables. Defaults to identity matrix. vcorr Variance-correlation matrix, can be specified instead of vcov (it is ignored if both are specified). beta Vector (or matrix with multiple responses) of effect sizes/slopes. Defaults to 1. fixed Logical, indicating whether the effects for the levels are fixed or to be simulated. If TRUE, beta represents the fixed effects. Defaults to FALSE. covariate Logical, indicating whether the indexes in the data structure are to be used as a continuous variable rather than simulating one. Defaults to FALSE. functions Vector - transformation to be applied to the response variable. Defaults to ‘identity’. "],["2-hierarchical.html", "2 Hierarchical structure", " 2 Hierarchical structure There are two parts to simulating hierarchical data. First you need to have a hierarchical data structure and second you need parameters at each of the different hierarchical levels. The data structure is essentially a data.frame (or matrix), with all the grouping factors and their levels, as we would see in a typical dataset. Lets take the blue tit dataset we explored earlier: data(BTdata) head(BTdata) ## tarsus back animal dam fosternest hatchdate sex ## 1 -1.89229718 1.1464212 R187142 R187557 F2102 -0.6874021 Fem ## 2 1.13610981 -0.7596521 R187154 R187559 F1902 -0.6874021 Male ## 3 0.98468946 0.1449373 R187341 R187568 A602 -0.4279814 Male ## 4 0.37900806 0.2555847 R046169 R187518 A1302 -1.4656641 Male ## 5 -0.07525299 -0.3006992 R046161 R187528 A2602 -1.4656641 Fem ## 6 -1.13519543 1.5577219 R187409 R187945 C2302 0.3502805 Fem Here animal, dam, fosternest and sex make up the data structure. In this Section, we will first demonstrate how to make a simple hierarchical structure using the make_structure function. simulate_population also allows pre-existing data structures to be incorporated into simulations. The remaining part of the section details how to simulate hierarchical data once you have a hierarchical data structure. "],["2.1-makestr.html", "2.1 Making a hierarchical structure", " 2.1 Making a hierarchical structure We can use the make_structure function to create nested and crossed hierarchical data structures. The make_structure function only produces balanced data structures, but these can be made unbalanced by sampling, which is outlined in Section 7 2.1.1 Single Factor Simplest structure - one grouping factor with multiple observations. Here we create a structure with 2 repeated observations of 5 individuals (small number are used here simply for illustration purposes). The structure contains the name of the grouping factors and their sample sizes, and repeat_obs is the number of repeated observations. make_structure(structure=&quot;individual(5)&quot;, repeat_obs=2) ## individual ## 1 1 ## 2 1 ## 3 2 ## 4 2 ## 5 3 ## 6 3 ## 7 4 ## 8 4 ## 9 5 ## 10 5 2.1.2 Nested factors If we want to have nested factors, so different hierarchical groups, where levels of one group only exist in one higher group then we can use the / symbol in the structure argument. For example, here we have 2 sexes, each with 5 individuals, with 2 repeated measurements each. make_structure(structure=&quot;sex(2)/individual(5)&quot;, repeat_obs=2) ## sex individual ## 1 1 1 ## 2 1 1 ## 3 1 2 ## 4 1 2 ## 5 1 3 ## 6 1 3 ## 7 1 4 ## 8 1 4 ## 9 1 5 ## 10 1 5 ## 11 2 6 ## 12 2 6 ## 13 2 7 ## 14 2 7 ## 15 2 8 ## 16 2 8 ## 17 2 9 ## 18 2 9 ## 19 2 10 ## 20 2 10 Note that in the nesting, the sample size for the lower group now represents the number within each level of the higher, rather than the total sample size, so overall there is 10 individuals. We can nest as much as we want: make_structure(structure=&quot;species(2)/population(2)/individual(2)&quot;, repeat_obs=2) ## species population individual ## 1 1 1 1 ## 2 1 1 1 ## 3 1 1 2 ## 4 1 1 2 ## 5 1 2 3 ## 6 1 2 3 ## 7 1 2 4 ## 8 1 2 4 ## 9 2 3 5 ## 10 2 3 5 ## 11 2 3 6 ## 12 2 3 6 ## 13 2 4 7 ## 14 2 4 7 ## 15 2 4 8 ## 16 2 4 8 2.1.3 Crossed factors We can create completely crossed factors - every combination of levels exists - using the + symbol in the structure argument make_structure(structure=&quot;treatment(2) + individual(5)&quot;, repeat_obs=1) ## treatment individual ## 1 1 1 ## 2 1 2 ## 3 1 3 ## 4 1 4 ## 5 1 5 ## 6 2 1 ## 7 2 2 ## 8 2 3 ## 9 2 4 ## 10 2 5 We can combine crossed and nested structures: make_structure(structure=&quot;treatment(2) + sex(2)/individual(5)&quot;, repeat_obs=1) ## treatment sex individual ## 1 1 1 1 ## 2 1 1 2 ## 3 1 1 3 ## 4 1 1 4 ## 5 1 1 5 ## 6 1 2 6 ## 7 1 2 7 ## 8 1 2 8 ## 9 1 2 9 ## 10 1 2 10 ## 11 2 1 1 ## 12 2 1 2 ## 13 2 1 3 ## 14 2 1 4 ## 15 2 1 5 ## 16 2 2 6 ## 17 2 2 7 ## 18 2 2 8 ## 19 2 2 9 ## 20 2 2 10 We can also output the crossed and nested using : make_structure(structure=&quot;treatment(2) + individual(5) + treatment:individual&quot;, repeat_obs=1) ## treatment individual treatment_individual ## 1 1 1 1 ## 2 1 2 2 ## 3 1 3 3 ## 4 1 4 4 ## 5 1 5 5 ## 6 2 1 6 ## 7 2 2 7 ## 8 2 3 8 ## 9 2 4 9 ## 10 2 5 10 2.1.4 Temporal structure ds &lt;- make_structure(structure=&quot;year(2)/month(12)/day(30)&quot;, repeat_obs=1) head(ds) ## year month day ## 1 1 1 1 ## 2 1 1 2 ## 3 1 1 3 ## 4 1 1 4 ## 5 1 1 5 ## 6 1 1 6 ds &lt;- make_structure(structure=&quot;year(2) + month(12) + day(30) + year:month:day&quot;, repeat_obs=1) head(ds) ## year month day year_month_day ## 1 1 1 1 1 ## 2 1 1 2 2 ## 3 1 1 3 3 ## 4 1 1 4 4 ## 5 1 1 5 5 ## 6 1 1 6 6 2.1.5 Naming factor levels Rather than just outputting 1 - N levels for the levels names of each factor, we might want to assign names. This can be done for all or some of the grouping factors, using the level_names argument. We can input a list, with an item in the list for each grouping factor we want to assign names, and then a vector of their names, which is the same length of the number of levels in that grouping factor. For example, below we just assign names to the two sexes: make_structure(structure=&quot;sex(2)/individual(5)&quot;, repeat_obs=2, level_names=list(sex=c(&quot;female&quot;,&quot;male&quot;))) ## sex individual ## 1 female 1 ## 2 female 1 ## 3 female 2 ## 4 female 2 ## 5 female 3 ## 6 female 3 ## 7 female 4 ## 8 female 4 ## 9 female 5 ## 10 female 5 ## 11 male 6 ## 12 male 6 ## 13 male 7 ## 14 male 7 ## 15 male 8 ## 16 male 8 ## 17 male 9 ## 18 male 9 ## 19 male 10 ## 20 male 10 And then to the individuals and the sexes make_structure(structure=&quot;sex(2)/individual(5)&quot;, repeat_obs=2, level_names=list(sex=c(&quot;female&quot;,&quot;male&quot;),individual=paste0(&quot;ind_&quot;,1:10))) ## sex individual ## 1 female ind_1 ## 2 female ind_1 ## 3 female ind_2 ## 4 female ind_2 ## 5 female ind_3 ## 6 female ind_3 ## 7 female ind_4 ## 8 female ind_4 ## 9 female ind_5 ## 10 female ind_5 ## 11 male ind_6 ## 12 male ind_6 ## 13 male ind_7 ## 14 male ind_7 ## 15 male ind_8 ## 16 male ind_8 ## 17 male ind_9 ## 18 male ind_9 ## 19 male ind_10 ## 20 male ind_10 "],["2.2-factors.html", "2.2 Factors", " 2.2 Factors In the first sections, we just simulated continuous predictors, varying at the level of the observation. However, we may want to simulate factors with known or fixed effects (i.e. not variables drawn randomly from a particular distribution) at different levels, such as sex or treatment effects. The first thing we want to do is specify a simple data structure, for example 100 observations for each of two sexes: ds &lt;- make_structure(structure=&quot;sex(2)&quot;, repeat_obs=100, level_names=list(sex=c(&quot;female&quot;,&quot;male&quot;))) Then we feed this data structure into the simulate_population() function using the data_structure argument. Note that we no longer need to specify the sample size (n), as this is taken from the number of rows in the data_structure. squid_data &lt;- simulate_population( data_structure = ds, parameters = ... ) In order to tell the parameter list we have effects that vary at different hierarchical levels, we can create additional slots in the parameter list for the grouping factors, so now it will look something like: squid_data &lt;- simulate_population( data_structure = ds, parameters = list( intercept = ..., sex = list( ... ), observation = list( ... ), residual = list( ... ) ) ) The names in the parameter list that relate to the different grouping factors either need to match the name in the data structure exactly (as above) or a ‘group’ argument needs to be given e.g. squid_data &lt;- simulate_population( data_structure = ds, parameters = list( intercept = ..., anything = list( group=&quot;sex,&quot; ... ), observation = list( ... ), residual = list( ... ) ) ) We then need to tell the parameters list that we have fixed effects for this grouping factor, in other words we know the difference in body size between the sexes is 0.5, for example. To do this we specify fixed = TRUE. squid_data &lt;- simulate_population( data_structure = ds, parameters = list( intercept = ..., anything = list( group=&quot;sex,&quot; ... ), observation = list( ... ), residual = list( ... ) ) ) We can then give a beta for all the different levels of that group. Note that there are two ways to specify this, as there also is in linear models in R. First, we can specify an intercept, and contrasts, equivalent to the output of lm(body_mass~sex), which involves specifying the beta for the first level as 0 to make it the baseline level (or any other level that you would like to be the baseline). squid_data &lt;- simulate_population( data_structure = ds, parameters = list( intercept= 10, sex=list( fixed=TRUE, beta=c(0,0.5) ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) boxplot( y ~ factor(sex), data) lm( y ~ factor(sex), data) ## ## Call: ## lm(formula = y ~ factor(sex), data = data) ## ## Coefficients: ## (Intercept) factor(sex)male ## 10.0947 0.4615 Alternately, we can specify no intercept (which defaults to 0), and the means for the two levels as betas( equivalent to lm(body_mass~0+sex)): squid_data &lt;- simulate_population( data_structure = ds, parameters = list( sex=list( fixed=TRUE, beta=c(10,10.5) ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) boxplot( y ~ factor(sex), data) lm( y ~ factor(sex), data) ## ## Call: ## lm(formula = y ~ factor(sex), data = data) ## ## Coefficients: ## (Intercept) factor(sex)male ## 10.100 0.521 lm( y ~ 0+factor(sex), data) ## ## Call: ## lm(formula = y ~ 0 + factor(sex), data = data) ## ## Coefficients: ## factor(sex)female factor(sex)male ## 10.10 10.62 We would recommend the former methods, as this makes things clearer if other factors are simulated. 2.2.1 Fixed Factor Interactions We might want to simulate an interaction between a continuous predictor and a factor, for example the effect of the environment varying between two sexes. Specifying this using simulate_population() is similar to interactions between two continuous predictors that we have previously encountered (Section 1.3). In the interaction part of the parameter list, we now specify the contrasts between the slopes for environment, using the names that we have assigned the different levels. In the simulation below, males are larger, and have a larger environment slope: squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;sex(2)&quot;, repeat_obs=1000), parameters = list( intercept=10, sex=list( fixed=TRUE, names=c(&quot;female&quot;,&quot;male&quot;), beta=c(0,0.5) ), observation= list( names = c(&quot;environment&quot;), beta =c(0.2) ), interactions = list( names=c(&quot;environment:male&quot;), beta = 0.4 ), residual = list( names=&quot;residual&quot;, vcov = 0.1 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y female male environment residual environment:male sex squid_pop ## 1 9.464227 1 0 -0.2306292 -0.48964724 0 1 1 ## 2 9.502465 1 0 0.3793662 -0.57340858 0 1 1 ## 3 10.064522 1 0 -1.6215884 0.38884003 0 1 1 ## 4 10.101917 1 0 -0.8841745 0.27875227 0 1 1 ## 5 10.099813 1 0 -0.7383195 0.24747643 0 1 1 ## 6 9.803504 1 0 -0.7874880 -0.03899826 0 1 1 plot(y~environment,data, pch=19, col=scales::alpha(c(1,2),0.5)[factor(data$sex)]) lm( y ~ 0 + factor(sex)*environment, data) ## ## Call: ## lm(formula = y ~ 0 + factor(sex) * environment, data = data) ## ## Coefficients: ## factor(sex)1 factor(sex)2 environment ## 9.9879 10.4875 0.1967 ## factor(sex)2:environment ## 0.4015 "],["2.3-simulating-predictors-at-different-hierarchical-levels.html", "2.3 Simulating predictors at different hierarchical levels", " 2.3 Simulating predictors at different hierarchical levels As well as simulating continuous predictors at the level of the observation, we can also simulate predictors at different hierarchical levels. Lets take the example of a situation where we have repeated measures of individuals. The individuals have traits that are consistently expressed, whilst the environment varies between observations. We can describe variation at these different hierarchical levels as: \\[ y_{ij} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta}_x + \\boldsymbol{u}_j \\boldsymbol{\\beta}_u + \\epsilon_{ij} \\] \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\boldsymbol{u}_j \\sim \\mathcal{N}(\\boldsymbol{\\mu}_u, \\Sigma_u) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] where \\(U\\) is a matrix of predictors that vary at the individual level (denoted by the subscript \\(j\\)), and \\(X\\) is a matrix of predictors at the observation level (denoted by the index \\(i\\)). In order to simulate from this model, we need a data structure and parameters for each of these levels. To do this, we can either specify a data structure generated using make_structure (outlined previously in Section 2.1), or a pre-existing data structure, to the simulate_population function. We then add in a item to the parameter list, the name of which matches on of the grouping factors in the data structure, and specify the parameters for predictors that vary at that level in the same way as outlined in the previous section (1). This is similar to the fixed factors above, but we are now assuming that the variable is drawn randomly from a distribution, rather than the effects at each level being fixed. Lets imagine that we simulate behaviour, that is a functions of an individual’s size and physiology, and also varies in response to the environment, here temperature and rainfall: squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;individual(500)&quot;, repeat_obs=2), parameters = list( individual = list( names = c(&quot;size&quot;,&quot;physiology&quot;), beta = c(0.1,0.2) ), observation = list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;), beta = c(0.2,-0.1) ), residual = list( vcov = 0.5 ) ), response_names=&quot;behaviour&quot; ) data &lt;- get_population_data(squid_data) coef(lm(behaviour ~ size + physiology + temperature + rainfall , data)) ## (Intercept) size physiology temperature rainfall ## 0.04239715 0.08633998 0.18335983 0.20147836 -0.08308933 Here, we have simulated 4 predictors, ‘size’ and ‘physiology’ that vary at the level of the individual, and ‘temperature’ and ‘rainfall’ that vary at the level of the observation. To keep things simple, we will simulate them all as unit normal variables (mean=0 and variance=1). Note, the names of the different grouping factors in the parameter list (here ‘individual’) needs to exactly match those in the data structure. The order does not, however, have to be the same. There are circumstances in which we may want to simulate two sets of effects at the same hierarchical level (for example see permanent environment effects in Section 4.1), in this case we can call them different things in the parameter list, but link them back to the grouping factor, by providing a group name. For example the following will produce the same simulation as above: squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;individual(500)&quot;, repeat_obs=2), parameters = list( ind1 = list( group=&quot;individual&quot;, names = c(&quot;size&quot;), beta = c(0.1) ), ind2 = list( group=&quot;individual&quot;, names = c(&quot;physiology&quot;), beta = c(0.2) ), observation = list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;), beta = c(0.2,-0.1) ), residual = list( vcov = 0.5 ) ), response_names=&quot;behaviour&quot; ) It is also worth noting that predictors do not have to be simulated for every grouping factor in the data structure - in this way no variation at that level can be simulated. 2.3.1 Simulating ‘random’ effects In essence, random effects (random intercepts) represent an unobserved/latent predictor (or group of predictors), which varies at a given hierarchical level. In a mixed effect model, the effect at each level of the grouping factor is unknown, and estimated by the model (and assumed to come from a normal distribution). When simulating this, however, we can simply simulate an additional predictor at a particular hierarchical level (\\(z\\)) with mean 0 and a given variance (\\(\\sigma^2_z\\)). \\[ y_{ij} = \\beta_0 + u_j + \\epsilon_{ij} \\] \\[ u_j \\sim \\mathcal{N}(0,\\sigma^2_u) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] For example we can simulate some between-individual variation as follows: squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;individual(500)&quot;, repeat_obs=2), parameters = list( individual = list( vcov = 0.5 ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y individual_effect residual individual squid_pop ## 1 -0.86084775 -0.09309309 -0.7677547 1 1 ## 2 -1.12731207 -0.09309309 -1.0342190 1 1 ## 3 1.75527564 1.62397047 0.1313052 2 1 ## 4 1.88106328 1.62397047 0.2570928 2 1 ## 5 0.08515369 -0.63170479 0.7168585 3 1 ## 6 -1.01588408 -0.63170479 -0.3841793 3 1 library(lme4) short_summary &lt;- function(x) print(summary(x), correlation=FALSE, show.resids=FALSE, ranef.comp = c(&quot;Variance&quot;)) short_summary(lmer(y ~ 1 + (1|individual), data)) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ 1 + (1 | individual) ## Data: data ## ## REML criterion at convergence: 2662.7 ## ## Random effects: ## Groups Name Variance ## individual (Intercept) 0.5209 ## Residual 0.4643 ## Number of obs: 1000, groups: individual, 500 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.01823 0.03881 0.47 Note that here we haven’t specified any variable names. In this case the simulated predictors are named by the grouping factors (e.g. individual_effects). 2.3.2 Incorporating existing data structures We could also use an existing data structure, taking the grouping factors and levels from an existing dataset and input them to simulate_population. To demonstrate this, we can use the blue tit dataset provided with the MCMCglmm package. This is a dataset with some continuous variables (tarsus, back (coloration) and hatchdate), and some grouping factors (animal, dam, fosternest and sex), the latter providing a data structure from which to simulate. library(MCMCglmm) data(BTdata) head(BTdata) ## tarsus back animal dam fosternest hatchdate sex ## 1 -1.89229718 1.1464212 R187142 R187557 F2102 -0.6874021 Fem ## 2 1.13610981 -0.7596521 R187154 R187559 F1902 -0.6874021 Male ## 3 0.98468946 0.1449373 R187341 R187568 A602 -0.4279814 Male ## 4 0.37900806 0.2555847 R046169 R187518 A1302 -1.4656641 Male ## 5 -0.07525299 -0.3006992 R046161 R187528 A2602 -1.4656641 Fem ## 6 -1.13519543 1.5577219 R187409 R187945 C2302 0.3502805 Fem squid_data &lt;- simulate_population( data_structure = BTdata[,c(&quot;dam&quot;,&quot;fosternest&quot;)], parameters = list( dam = list( vcov = 0.2 ), fosternest = list( vcov = 0.3 ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y dam_effect fosternest_effect residual dam fosternest ## 1 -0.9961429 0.32127788 -0.5187692 -0.79865156 R187557 F2102 ## 2 0.4241295 -0.25097001 0.8402955 -0.16519603 R187559 F1902 ## 3 -1.3080452 0.14237053 -0.1642529 -1.28616283 R187568 A602 ## 4 -0.5971299 -0.07265687 -0.7234984 0.19902540 R187518 A1302 ## 5 -1.4897618 -0.93654434 -0.6329443 0.07972682 R187528 A2602 ## 6 -1.3758694 0.02953667 0.4727818 -1.87818792 R187945 C2302 ## squid_pop ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 "],["2.4-randomslopes.html", "2.4 Random Regression", " 2.4 Random Regression Random regression (or a random intercepts and slopes model) essentially represents an interaction (or product) between predictors at different levels, with the random slopes being an unobserved, latent variable (\\(u_2\\)). \\[ y_{ij} = \\beta_0 + \\beta_1x_{i} + u_{1j} + u_{2j}x_{i} + \\epsilon_{ij} \\] \\[ x_i \\sim \\mathcal{N}(0,\\sigma^2_{x}) \\] \\[ \\boldsymbol{u}_i \\sim \\mathcal{N}(0, \\Sigma_u) \\] \\[ \\epsilon \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] We can specify random slopes by simulating a slopes variable at the individual level (ind_slope - \\(u_{2}\\)). We can specify the mean environmental effect the slope of the environmental variable (\\(beta_1\\)). \\(u_{2}\\) then represents the deviations from the mean slope (this is typically how it is modelled in a linear mixed effect model). Importantly the beta parameter associated with ind_slope is specified as 0 (there is no ‘main effect’ of the slopes, just the interaction), and the beta parameter associated with interaction is 1. squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(300)&quot;,repeat_obs=10), parameters = list( individual = list( names = c(&quot;ind_int&quot;,&quot;ind_slope&quot;), beta = c(1,0), vcov = c(1,0.5) ), observation= list( names = c(&quot;environment&quot;), beta = c(0.2) ), residual = list( vcov = c(0.5) ), interactions = list( names = c(&quot;ind_slope:environment&quot;), beta = c(1) ) ) ) data &lt;- get_population_data(squid_data) short_summary(lmer(y ~ environment + (1+environment|individual),data)) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ environment + (1 + environment | individual) ## Data: data ## ## REML criterion at convergence: 7970.8 ## ## Random effects: ## Groups Name Variance Corr ## individual (Intercept) 1.0903 ## environment 0.4959 0.11 ## Residual 0.4868 ## Number of obs: 3000, groups: individual, 300 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) -0.08657 0.06175 -1.402 ## environment 0.26278 0.04335 6.062 We can make the link between the code and the equation more explicit, by expanding out the equation: \\[ y_{ij} = \\beta_0 + \\beta_xx_{i} + \\boldsymbol{u}_j \\boldsymbol{\\beta}_u + \\beta_{ux}u_{2j}x_{i} + \\epsilon_{ij} \\] \\[ \\color{CornflowerBlue}{\\boldsymbol{\\beta_u} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}} , \\color{orange}{\\beta_{ux}=1} \\] squid_data &nbsp;&nbsp;data_structure=make_structure(\"individual(300)\",repeat_obs=10),&nbsp;&nbsp;parameters = list(&nbsp;&nbsp;&nbsp;&nbsp;individual = list(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;names = c(\"ind_int\",\"ind_slope\"), &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;beta = c(1,0),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vcov = c(1,0.5)&nbsp;&nbsp;&nbsp;&nbsp;),&nbsp;&nbsp;&nbsp;&nbsp;observation= list(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;names = c(\"environment\"),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;beta = c(0.2)&nbsp;&nbsp;&nbsp;&nbsp;), &nbsp;&nbsp;&nbsp;&nbsp;residual = list(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vcov = c(0.5)&nbsp;&nbsp;&nbsp;&nbsp;),&nbsp;&nbsp;&nbsp;&nbsp;interactions = list(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;names = c(\"ind_slope:environment\"),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;beta = c(1)&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;)) Here we have specified no correlation between intercepts and slopes. To simulate a covariance/correlation between intercepts and slopes, we can simply give the vcov argument a covariance matrix, instead of two variances: squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(300)&quot;,repeat_obs=10), parameters = list( individual = list( names = c(&quot;ind_int&quot;,&quot;ind_slope&quot;), beta = c(1,0), vcov = matrix(c(1,0.3,0.3,0.5),ncol=2,nrow=2,byrow=TRUE) ), observation= list( names = c(&quot;environment&quot;), beta = c(0.2) ), residual = list( vcov = c(0.5) ), interactions = list( names = c(&quot;ind_slope:environment&quot;), beta = c(1) ) ) ) data &lt;- get_population_data(squid_data) short_summary(lmer(y ~ environment + (1+environment|individual),data)) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ environment + (1 + environment | individual) ## Data: data ## ## REML criterion at convergence: 7758.2 ## ## Random effects: ## Groups Name Variance Corr ## individual (Intercept) 0.9658 ## environment 0.5199 0.57 ## Residual 0.4663 ## Number of obs: 3000, groups: individual, 300 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.03375 0.05824 0.580 ## environment 0.26242 0.04404 5.959 "],["2.5-BetweenWithin.html", "2.5 Between- and within-group effects", " 2.5 Between- and within-group effects We may want to simulate the case where a predictor variable varies both within and between groups - in other words it is repeatable at the group level. For example, if we are simulating body mass, we might expect that body mass is a function of an environmental variable, rainfall, and that differs systematically between individuals, as well as within, for example due to spatial variation in where individual lives. The simplest way of simulating this is as two rainfall variables, one at the level of the individual and one at the level of the observation, something like: squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(100)&quot;, repeat_obs=5), parameters = list( individual=list( names=c(&quot;between_rainfall&quot;), ... ), observation=list( names=c(&quot;within_rainfall&quot;), ... ), residual=list( ... ) ) ) We can then specify the variation in rainfall within and between individuals, for example, if the repeatability of rainfall amongst individuals is 0.5, and the total variance in rainfall is 0.8, we would make the variance in rainfall 0.4 at each level: squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(100)&quot;, repeat_obs=5), parameters = list( individual=list( names=c(&quot;between_rainfall&quot;), vcov=0.4, ... ), observation=list( names=c(&quot;within_rainfall&quot;), vcov=0.4, ... ), residual=list( 0.8 ) ) ) If we want the rainfall variable to have a mean that is not 0, we should specify this in only one place, as otherwise they will add up weirdly! squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(100)&quot;, repeat_obs=5), parameters = list( individual=list( names=c(&quot;between_rainfall&quot;), vcov=0.4, ... ), observation=list( names=c(&quot;within_rainfall&quot;), vcov=0.4, mean=10 ), residual=list( 0.8 ) ) ) Now we want to add in some betas. If the effect of rainfall on body mass is causal, we would expect the beta to be the same at both levels - this results as a simple reorganisation of the model equation. We start with an effect of rainfall on body size \\[ y_i = \\beta_0 + \\beta_1 (x_{ij}) + \\epsilon_i \\] where \\(x_{ij}\\) is rainfall varying at levels \\(i\\) (observation) and \\(j\\) (individual). We can split rainfall up into within (\\(x_{1i}\\)) and between (\\(u_{1i}\\)) individual components: \\[ y_i = \\beta_0 + \\beta_1 (u_{j} + x_{i}) + \\epsilon_i \\] \\[ y_i = \\beta_0 + \\beta_1u_{j} + \\beta_{1}x_{i} + \\epsilon_i \\] you see that the coefficients should be the same. squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(100)&quot;, repeat_obs=5), parameters = list( individual=list( names=c(&quot;between_env&quot;, &quot;ind_int&quot;), vcov=c(0.5,1), beta=c(-2,1) ), observation=list( names=c(&quot;within_env&quot;), vcov=c(0.5), beta=c(2) ), residual=list( vcov=1 ) ) ) data &lt;- get_population_data(squid_data) data$environment &lt;- data$between_env + data$within_env "],["3-multivariate.html", "3 Multi-response Models", " 3 Multi-response Models We can simulate multiple response variables, that covary at different hierarchical levels. In the case of a simple random effects model, we can have a covariance matrix at each level, \\[ \\boldsymbol{y}_{ij} = \\boldsymbol{\\beta}_0 + \\boldsymbol{u}_j + \\boldsymbol{\\epsilon}_{ij} \\] \\[ \\boldsymbol{u}_i \\sim \\mathcal{N}(0, \\Sigma_u) \\] \\[ \\boldsymbol{\\epsilon}_{i} \\sim \\mathcal{N}(0, \\Sigma_{\\epsilon}) \\] We can indicate that there are multiple phenotypes within the parameter list in two ways. First, we can use n_response in the parameter list, and specifying the covariance matrix (vcov) at each level. In this way we can simulate covariance at each level. squid_data &lt;- simulate_population( data_structure=make_structure(structure = &quot;individual(100)&quot;,repeat_obs=10), n_response = 2, parameters=list( individual = list( vcov = matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ), residual = list( vcov = matrix(c(1,0.5,0.5,1),nrow = 2,ncol = 2,byrow=TRUE) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y1 y2 individual_effect1 individual_effect2 residual1 ## 1 1.7154548 -0.3400219 1.917971 0.7785752 -0.2025162 ## 2 0.5628202 0.3404365 1.917971 0.7785752 -1.3551508 ## 3 2.2598837 0.1039745 1.917971 0.7785752 0.3419127 ## 4 1.2400569 1.7172877 1.917971 0.7785752 -0.6779141 ## 5 0.8401039 0.2945199 1.917971 0.7785752 -1.0778671 ## 6 2.6972366 0.0814206 1.917971 0.7785752 0.7792656 ## residual2 individual squid_pop ## 1 -1.1185971 1 1 ## 2 -0.4381387 1 1 ## 3 -0.6746007 1 1 ## 4 0.9387125 1 1 ## 5 -0.4840553 1 1 ## 6 -0.6971546 1 1 The formulation above (just random effects), can be simulated in a similar way with beta as an identity matrix (i.e. a predictor for each trait). squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;individual(100)&quot;,repeat_obs=10), n_response=2, parameters=list( individual = list( vcov =matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE), beta= diag(2) ), residual = list( vcov =matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE), beta= diag(2) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y1 y2 individual_effect1 individual_effect2 residual1 ## 1 -1.7790297 -2.1313181 -0.2306292 0.2132262 -1.5484005 ## 2 0.9989910 1.5914308 -0.2306292 0.2132262 1.2296201 ## 3 0.5519600 0.4977197 -0.2306292 0.2132262 0.7825892 ## 4 0.8959494 0.9204513 -0.2306292 0.2132262 1.1265785 ## 5 0.5997486 0.8608984 -0.2306292 0.2132262 0.8303778 ## 6 -1.4619544 -0.8689692 -0.2306292 0.2132262 -1.2313253 ## residual2 individual squid_pop ## 1 -2.3445443 1 1 ## 2 1.3782046 1 1 ## 3 0.2844935 1 1 ## 4 0.7072251 1 1 ## 5 0.6476722 1 1 ## 6 -1.0821955 1 1 # library(MCMCglmm) # mod &lt;- MCMCglmm(cbind(y1,y2)~1,random=~us(trait):individual, rcov=~us(trait):units,data=data,family=rep(&quot;gaussian&quot;,2),verbose=FALSE) # summary(mod) Second, we can build up predictors at each level that drive this covariance. Here we make beta into a matrix (\\(B\\)), with predictors as rows, and responses as columns. \\[\\boldsymbol{y}_{ij} = \\boldsymbol{\\beta}_0 + \\boldsymbol{x}_{i} B_x + \\boldsymbol{u}_j + \\boldsymbol{\\epsilon}_{ij}\\] \\[\\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x)\\] \\[\\boldsymbol{u}_i \\sim \\mathcal{N}(0, \\Sigma_u)\\] \\[\\boldsymbol{\\epsilon}_{i} \\sim \\mathcal{N}(0, \\Sigma_{\\epsilon})\\] Alternatively, you could also create multivariate phenotypes being affected by the same predictors. Here we have two phenotypes, affected by three predictors, and so we can create a 3x2 matrix of betas beta &lt;- matrix(c( 0.5, 0.1, 0.2, 0.2, 0.3, 0.1 ),nrow=3,ncol=2,byrow=TRUE) beta ## [,1] [,2] ## [1,] 0.5 0.1 ## [2,] 0.2 0.2 ## [3,] 0.3 0.1 squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;individual(100)&quot;,repeat_obs=20), n_response=2, parameters= list( individual = list( vcov =matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ), observation = list( names = c(&quot;temperature&quot;, &quot;rainfall&quot;, &quot;wind&quot;), beta= beta ), residual = list( vcov= matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y1 y2 individual_effect1 individual_effect2 temperature ## 1 1.22310660 0.5923479 0.3440492 0.579633 1.5166067 ## 2 1.41370650 -0.1014570 0.3440492 0.579633 1.4510438 ## 3 0.61015279 -0.4051245 0.3440492 0.579633 0.6377108 ## 4 0.52717455 1.4791758 0.3440492 0.579633 -0.4579670 ## 5 0.36549918 0.3292956 0.3440492 0.579633 0.3432748 ## 6 0.06027212 -0.4377444 0.3440492 0.579633 0.1036752 ## rainfall wind residual1 residual2 individual squid_pop ## 1 0.6364945 -0.00366005 -0.005446858 -0.2658786 1 1 ## 2 0.2034993 0.19014050 0.246393344 -0.8859082 1 1 ## 3 -2.3866566 0.05766300 0.407280601 -0.5769636 1 1 ## 4 0.1370347 1.41738837 -0.040514635 0.7761938 1 1 ## 5 0.5636609 -0.85833490 -0.005419163 -0.3115636 1 1 ## 6 -0.4653576 1.49089522 -0.689811760 -1.0837629 1 1 # library(MCMCglmm) # mod &lt;- MCMCglmm(cbind(y1,y2)~1,random=~us(trait):individual, rcov=~us(trait):units,data=data,family=rep(&quot;gaussian&quot;,2),verbose=FALSE) # summary(mod) squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;individual(100)&quot;,repeat_obs=20), n_response=2, parameters= list( individual = list( vcov =matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ), observation = list( names = c(&quot;temperature&quot;, &quot;rainfall&quot;, &quot;wind&quot;), beta= beta ), interactions = list( names = c(&quot;temperature:rainfall&quot;), beta=matrix(c(0.1,-0.3),ncol=2,byrow=TRUE) ), residual = list( vcov= matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y1 y2 individual_effect1 individual_effect2 temperature ## 1 2.21050134 1.294281304 0.3738621 0.3130563 0.2474442 ## 2 0.30671985 0.767288962 0.3738621 0.3130563 0.6267361 ## 3 -0.08741854 -0.675319438 0.3738621 0.3130563 1.4255186 ## 4 0.98283306 -0.002284301 0.3738621 0.3130563 0.8091150 ## 5 2.78888855 1.180712862 0.3738621 0.3130563 0.1566717 ## 6 1.59693774 0.290589001 0.3738621 0.3130563 1.0819382 ## rainfall wind residual1 residual2 temperature:rainfall individual ## 1 0.07576161 1.40470231 1.2744794 0.8064820 0.01874677 1 ## 2 0.49027116 -0.02155445 -0.5028253 0.3878414 0.30727064 1 ## 3 -0.68348827 -0.56325151 -0.7709343 -1.2302024 -0.97432525 1 ## 4 0.92104163 0.76022751 -0.2823860 -0.4329146 0.74522861 1 ## 5 -1.25575415 1.41897367 2.1818234 0.9022205 -0.19674116 1 ## 6 0.95321639 2.08038728 -0.2357851 -0.2199468 1.03132125 1 ## squid_pop ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 # library(MCMCglmm) # mod &lt;- MCMCglmm(cbind(y1,y2)~1,random=~us(trait):individual, rcov=~us(trait):units,data=data,family=rep(&quot;gaussian&quot;,2),verbose=FALSE) # summary(mod) "],["3.1-one-response-repeatedly-measured-the-other-not.html", "3.1 One response repeatedly measured, the other not", " 3.1 One response repeatedly measured, the other not set the beta values for the trait that is unmeasured at a particular level to 0 The other way to do this is through sampling (link and example needed) individual &lt;- list( vcov = matrix(c( 1,0.5, 0.5,1 ),nrow=2,ncol=2,byrow=TRUE) ) residual &lt;- list( vcov = matrix(c( 1,0.5, 0.5,1 ),nrow = 2,ncol = 2,byrow=TRUE), beta = matrix(c( 1,0, 0,0 ),nrow = 2,ncol = 2,byrow=TRUE) ) squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;individual(100)&quot;,repeat_obs=20), n_response = 2, parameters=list(individual = individual, residual = residual) ) data &lt;- get_population_data(squid_data) "],["3.2-different-distributions.html", "3.2 Different distributions", " 3.2 Different distributions individual &lt;- list( vcov = matrix(c( 1,0.5, 0.5,1 ),nrow=2,ncol=2,byrow=TRUE) ) residual &lt;- list( vcov = matrix(c( 1,0.5, 0.5,1 ),nrow = 2,ncol = 2,byrow=TRUE), beta = matrix(c( 1,0, 0,0 ),nrow = 2,ncol = 2,byrow=TRUE) ) squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;individual(100)&quot;,repeat_obs=20), n_response = 2, parameters=list(individual = individual, residual = residual), family=c(&quot;gaussian&quot;,&quot;binomial&quot;), link=c(&quot;identity&quot;,&quot;logit&quot;) ) data &lt;- get_population_data(squid_data) head(data,20) ## y1 y2 individual_effect1 individual_effect2 residual1 residual2 ## 1 -1.6706436 0 -1.085769 -1.809539 -0.5848745 -1.10098411 ## 2 -1.4666490 0 -1.085769 -1.809539 -0.3808800 -1.10359510 ## 3 -0.7798335 0 -1.085769 -1.809539 0.3059355 0.89906527 ## 4 -0.6755392 0 -1.085769 -1.809539 0.4102298 1.27144736 ## 5 -1.4314630 0 -1.085769 -1.809539 -0.3456940 1.47579179 ## 6 -2.0038855 0 -1.085769 -1.809539 -0.9181164 -1.71020015 ## 7 0.3282533 0 -1.085769 -1.809539 1.4140223 -1.38338556 ## 8 -0.8040910 0 -1.085769 -1.809539 0.2816781 1.12610799 ## 9 -2.4921780 0 -1.085769 -1.809539 -1.4064089 -0.83539112 ## 10 0.5833605 0 -1.085769 -1.809539 1.6691295 2.18371514 ## 11 -1.6705681 0 -1.085769 -1.809539 -0.5847991 0.44656648 ## 12 -2.0109248 0 -1.085769 -1.809539 -0.9251558 -1.22703322 ## 13 0.1975017 0 -1.085769 -1.809539 1.2832708 1.63331381 ## 14 -4.1406047 0 -1.085769 -1.809539 -3.0548357 -1.46211542 ## 15 -0.7559031 0 -1.085769 -1.809539 0.3298660 -1.24415539 ## 16 -0.1440253 0 -1.085769 -1.809539 0.9417437 -1.04997775 ## 17 -0.1195880 0 -1.085769 -1.809539 0.9661811 1.52189122 ## 18 -1.6872446 0 -1.085769 -1.809539 -0.6014755 -0.86684664 ## 19 -0.7503544 0 -1.085769 -1.809539 0.3354147 0.02700792 ## 20 -0.4113180 0 -1.085769 -1.809539 0.6744510 0.15798303 ## individual squid_pop ## 1 1 1 ## 2 1 1 ## 3 1 1 ## 4 1 1 ## 5 1 1 ## 6 1 1 ## 7 1 1 ## 8 1 1 ## 9 1 1 ## 10 1 1 ## 11 1 1 ## 12 1 1 ## 13 1 1 ## 14 1 1 ## 15 1 1 ## 16 1 1 ## 17 1 1 ## 18 1 1 ## 19 1 1 ## 20 1 1 data &lt;- get_population_data(squid_data) "],["3.3-multivariate-random-slopes.html", "3.3 Multivariate Random Slopes", " 3.3 Multivariate Random Slopes Before reading this it is worth checking out how to simulate univariate random slopes in Section 2.4. Here we have to think about the beta matrix. As we saw in an example above, in multivariate models beta can be thought of as switching on and off predictor variables for the response variables. We we can simulate 4 variables, an intercept and slope for each variable, and then use the beta matrix to tell simulate_population which response variable they link to individual &lt;- list( names = c(&quot;ind_int1&quot;,&quot;ind_slope1&quot;,&quot;ind_int2&quot;,&quot;ind_slope2&quot;), vcov = matrix(c( 1, 0.5, 0, 0, 0.5, 1, 0, 0, 0, 0, 1, 0.2, 0, 0, 0.2, 1 ),nrow=4,ncol=4, byrow=TRUE), beta = matrix(c( 1, 0, 0, 0, 0, 1, 0, 0 ),nrow = 4,ncol = 2, byrow=TRUE) ) observation &lt;- list( names=&quot;environment&quot;, beta=matrix(c(0.5,-0.3), ncol=2,byrow=TRUE) ) residual &lt;- list( vcov = matrix(c( 1,0.5, 0.5,1 ),nrow = 2,ncol = 2,byrow=TRUE) ) interactions &lt;- list( names=c(&quot;ind_slope1:environment&quot;,&quot;ind_slope2:environment&quot;), beta= matrix(c( 1,0, 0,1 ), ncol=2,byrow=TRUE) ) squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;individual(100)&quot;,repeat_obs=20), n_response = 2, parameters=list( individual = individual, observation = observation, residual = residual, interactions = interactions ) ) data &lt;- get_population_data(squid_data) head(data,20) ## y1 y2 ind_int1 ind_slope1 ind_int2 ind_slope2 environment ## 1 -2.8929785 -1.80978534 0.0588518 1.085178 0.1617523 0.5981975 -0.99200736 ## 2 -1.3637066 -0.91976972 0.0588518 1.085178 0.1617523 0.5981975 0.41084465 ## 3 2.9575947 -0.26204801 0.0588518 1.085178 0.1617523 0.5981975 1.24627785 ## 4 -0.4513149 -0.36115761 0.0588518 1.085178 0.1617523 0.5981975 -0.07999263 ## 5 1.4708316 1.54949605 0.0588518 1.085178 0.1617523 0.5981975 0.60692362 ## 6 1.8250487 -0.18599499 0.0588518 1.085178 0.1617523 0.5981975 0.98080842 ## 7 -1.0226457 -0.47901527 0.0588518 1.085178 0.1617523 0.5981975 -0.11309214 ## 8 0.5126517 1.07530623 0.0588518 1.085178 0.1617523 0.5981975 -0.45103722 ## 9 1.3306505 -1.36650396 0.0588518 1.085178 0.1617523 0.5981975 0.71480299 ## 10 -2.3825997 0.05147684 0.0588518 1.085178 0.1617523 0.5981975 -2.54734658 ## 11 2.5459297 0.34937111 0.0588518 1.085178 0.1617523 0.5981975 1.39594598 ## 12 1.0908831 -1.83828245 0.0588518 1.085178 0.1617523 0.5981975 0.54874017 ## 13 -0.1222957 -0.13303389 0.0588518 1.085178 0.1617523 0.5981975 -0.02931245 ## 14 2.7255433 0.90984488 0.0588518 1.085178 0.1617523 0.5981975 1.82736314 ## 15 0.4693991 -0.35557207 0.0588518 1.085178 0.1617523 0.5981975 0.03022781 ## 16 -1.6923948 1.45885249 0.0588518 1.085178 0.1617523 0.5981975 -1.28777736 ## 17 -2.3801511 -1.96969000 0.0588518 1.085178 0.1617523 0.5981975 -1.18116780 ## 18 0.9086790 0.45014096 0.0588518 1.085178 0.1617523 0.5981975 -0.04292380 ## 19 0.6281504 0.43513773 0.0588518 1.085178 0.1617523 0.5981975 -0.23437953 ## 20 0.5003277 1.47204209 0.0588518 1.085178 0.1617523 0.5981975 -0.57500082 ## residual1 residual2 ind_slope1:environment ind_slope2:environment ## 1 -1.3793220 -1.6757235 -1.07650459 -0.59341631 ## 2 -2.0738203 -1.2040348 0.44583958 0.24576623 ## 3 0.9231706 -0.7954372 1.35243333 0.74552027 ## 4 -0.3833642 -0.4990563 -0.08680624 -0.04785139 ## 5 0.4498978 1.2067607 0.65862018 0.36306018 ## 6 0.2114410 -0.6402219 1.06435175 0.58671713 ## 7 -0.9022263 -0.6070438 -0.12272511 -0.06765143 ## 8 1.1687742 1.0480521 -0.48945568 -0.26980933 ## 9 0.1387087 -1.7414087 0.77568850 0.42759335 ## 10 1.5965463 0.6493369 -2.76432453 -1.52381630 ## 11 0.2742550 -0.2286488 1.51484990 0.83505137 ## 12 0.1621804 -2.1636677 0.59548078 0.32825499 ## 13 -0.1346820 -0.2860453 -0.03180923 -0.01753464 ## 14 -0.2300044 0.2031775 1.98301433 1.09312403 ## 15 0.3626309 -0.5263382 0.03280255 0.01808220 ## 16 0.2901097 1.6811122 -1.39746770 -0.77034518 ## 17 -0.5666417 -1.7792210 -1.28177734 -0.70657160 ## 18 0.9178691 0.3011884 -0.04657996 -0.02567691 ## 19 0.9408319 0.3432768 -0.25434351 -0.14020524 ## 20 1.3529545 1.4817536 -0.62397825 -0.34396404 ## individual squid_pop ## 1 1 1 ## 2 1 1 ## 3 1 1 ## 4 1 1 ## 5 1 1 ## 6 1 1 ## 7 1 1 ## 8 1 1 ## 9 1 1 ## 10 1 1 ## 11 1 1 ## 12 1 1 ## 13 1 1 ## 14 1 1 ## 15 1 1 ## 16 1 1 ## 17 1 1 ## 18 1 1 ## 19 1 1 ## 20 1 1 "],["4-animal.html", "4 Genetic effects", " 4 Genetic effects This vignette assumes that you are generally happy with how the sim_population() function works. "],["4.1-va.html", "4.1 Additive genetics effects", " 4.1 Additive genetics effects In order to simulate breeding values (additive genetic effects), we can provide the simulate_population() function with the relatedness structure in the population. The simplest way to do this is providing a pedigree using the the pedigree argument (a genetic relatedness matrix could also be given to the cov_str argument). The input to this argument needs to be a list, and the name of the pedigree in the list links it with the item in the parameter list. NOTE the simulate_population function has very little error checking of pedigree structure at the moment When simulating breeding values, all individuals in pedigree need to be in the data_structure and vice versa. Having unsampled individuals (for example the base population) can be achieved in the sampling stage (not implemented yet). Lets start by importing a pedigree library(MCMCglmm) data(BTped) head(BTped) ## animal dam sire ## 1 R187557 &lt;NA&gt; &lt;NA&gt; ## 2 R187559 &lt;NA&gt; &lt;NA&gt; ## 3 R187568 &lt;NA&gt; &lt;NA&gt; ## 4 R187518 &lt;NA&gt; &lt;NA&gt; ## 5 R187528 &lt;NA&gt; &lt;NA&gt; ## 6 R187945 &lt;NA&gt; &lt;NA&gt; We can use this pedigree as a data_structure squid_data &lt;- simulate_population( data_structure = BTped, pedigree = list(animal=BTped), parameters =list( animal = list( vcov = 0.2 ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y animal_effect residual animal dam sire squid_pop ## R187557 0.001049242 0.2717576 -0.2707083 R187557 &lt;NA&gt; &lt;NA&gt; 1 ## R187559 0.337915749 0.6864674 -0.3485517 R187559 &lt;NA&gt; &lt;NA&gt; 1 ## R187568 -0.733484258 -0.1971984 -0.5362859 R187568 &lt;NA&gt; &lt;NA&gt; 1 ## R187518 0.780509757 0.2115614 0.5689484 R187518 &lt;NA&gt; &lt;NA&gt; 1 ## R187528 0.198435519 0.3475518 -0.1491163 R187528 &lt;NA&gt; &lt;NA&gt; 1 ## R187945 -0.854447851 -0.2441706 -0.6102772 R187945 &lt;NA&gt; &lt;NA&gt; 1 # Ainv&lt;-inverseA(BTped)$Ainv # mod &lt;- MCMCglmm(y~1, random=~ animal,data=data,ginverse=list(animal=Ainv),verbose=FALSE) # summary(mod) We might want to simulate repeated measurements to allow estimation of permanent environment effects. This is where being able to have something in the parameter list with a different name to the grouping factor is useful. In this way permanent environmental and additive genetic effects can be simulated in different parts of the parameter list, and linked to the same part of the data_structure. ## make data structure with two observations per individual ds &lt;- data.frame(individual=rep(BTped[,1], 2)) squid_data &lt;- simulate_population( data_structure = ds, pedigree=list(animal=BTped), parameters = list( individual = list( vcov = 0.3 ), animal = list( group=&quot;individual&quot;, vcov = 0.2 ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y individual_effect animal_effect residual individual ## R187888 -0.7747080 -0.48545266 0.34386743 -0.6331228 R187557 ## R187646 1.2637980 1.19344724 0.23622685 -0.1658761 R187559 ## R187330 1.2315559 0.03483088 0.58394160 0.6127834 R187568 ## R187374 -0.4667102 -0.64830239 0.03600587 0.1455863 R187518 ## R187225 0.5837659 0.69669125 0.14473226 -0.2576576 R187528 ## R187133 -0.1058035 -0.54704434 0.06288580 0.3783550 R187945 ## squid_pop ## R187888 1 ## R187646 1 ## R187330 1 ## R187374 1 ## R187225 1 ## R187133 1 # Ainv&lt;-inverseA(BTped)$Ainv # data$animal_id &lt;- data$individual # mod &lt;- MCMCglmm(y~1, random=~ individual + animal_id,data=data,ginverse=list(animal_id=Ainv),verbose=FALSE) # summary(mod) "],["4.2-multivariate-genetic-effects.html", "4.2 Multivariate genetic effects", " 4.2 Multivariate genetic effects We can simulate genetic effects affecting multiple phenotypes and the covariance between them, by specifying the number of response variables, and a covariance matrix, instead of only a variance. squid_data &lt;- simulate_population( data_structure = BTped, pedigree = list(animal = BTped), n_response=2, parameters = list( animal = list( vcov = diag(2) ), residual = list( vcov = diag(2) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y1 y2 animal_effect1 animal_effect2 residual1 ## R187557 0.2270163 0.7349977 -0.14996162 -0.9763782 0.3769779 ## R187559 0.8121651 2.6809126 -0.20470701 1.8215682 1.0168721 ## R187568 -2.3218758 -1.3770079 -1.83531039 0.2799440 -0.4865654 ## R187518 -1.5891070 -1.5192159 -0.23712091 -0.2315827 -1.3519861 ## R187528 0.6954574 -2.1002711 0.05902919 -1.5265765 0.6364282 ## R187945 -2.9368649 -0.3194446 -1.38312923 0.9299490 -1.5537356 ## residual2 animal dam sire squid_pop ## R187557 1.7113759 R187557 &lt;NA&gt; &lt;NA&gt; 1 ## R187559 0.8593444 R187559 &lt;NA&gt; &lt;NA&gt; 1 ## R187568 -1.6569519 R187568 &lt;NA&gt; &lt;NA&gt; 1 ## R187518 -1.2876332 R187518 &lt;NA&gt; &lt;NA&gt; 1 ## R187528 -0.5736946 R187528 &lt;NA&gt; &lt;NA&gt; 1 ## R187945 -1.2493935 R187945 &lt;NA&gt; &lt;NA&gt; 1 # Ainv&lt;-inverseA(BTped)$Ainv # mod &lt;- MCMCglmm(cbind(y1,y2)~1,random=~us(trait):animal, rcov=~us(trait):units,data=data,family=rep(&quot;gaussian&quot;,2),verbose=FALSE,ginverse=list(animal=Ainv)) # summary(mod) "],["4.3-sex-specific-genetic-variance-and-inter-sexual-genetic-correlations.html", "4.3 Sex specific genetic variance and inter-sexual genetic correlations", " 4.3 Sex specific genetic variance and inter-sexual genetic correlations ds &lt;- data.frame(animal=BTped[,&quot;animal&quot;],sex=sample(c(&quot;Female&quot;,&quot;Male&quot;),nrow(BTped), replace=TRUE)) squid_data &lt;- simulate_population( parameters = list( sex=list( fixed=TRUE, names=c(&quot;female&quot;,&quot;male&quot;), beta=c(-0.5,0.5) ), animal= list( names = c(&quot;G_female&quot;,&quot;G_male&quot;), vcov =matrix(c(0.1,-0.1,-0.1,0.4), nrow=2, ncol=2 ,byrow=TRUE) ), residual = list( names=&quot;residual&quot;, vcov = 0.1 ) ), data_structure = ds, pedigree = list(animal=BTped), model = &quot;y = female + male + I(female)*G_female + I(male)*G_male + residual&quot; ) data &lt;- get_population_data(squid_data) head(data) ## y female male G_female G_male residual animal sex ## 1 -0.07664521 1 0 0.2153092 -0.277927530 0.20804561 R187557 Female ## 2 0.32705982 0 1 0.2120106 -0.195909978 0.02296980 R187559 Male ## 3 -0.32068808 0 1 0.2096736 -0.378169745 -0.44251833 R187568 Male ## 4 0.89896430 0 1 0.1734671 -0.157022020 0.55598632 R187518 Male ## 5 0.46138651 0 1 -0.5514875 -0.075445373 0.03683188 R187528 Male ## 6 0.51619286 0 1 0.4333079 -0.004309735 0.02050260 R187945 Male ## squid_pop ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 par(mfrow=c(1,2)) boxplot(y~factor(sex),data) plot(G_female~G_male,data) "],["4.4-gxe.html", "4.4 GxE", " 4.4 GxE squid_data &lt;- simulate_population( parameters = list( animal = list( names = c(&quot;G_int&quot;,&quot;G_slope&quot;), mean =c(0,0.2), vcov =matrix(c(1,0.3,0.3,0.5),ncol=2,nrow=2,byrow=TRUE) ), observation= list( names = c(&quot;environment&quot;), vcov =c(1) ), residual = list( names = c(&quot;residual&quot;), vcov =c(0.5) ) ), data_structure=rbind(BTped,BTped,BTped,BTped,BTped), pedigree = list(animal=BTped), model=&quot;y = G_int + G_slope * environment + residual&quot; ) data &lt;- get_population_data(squid_data) library(lme4) short_summary &lt;- function(x) print(summary(x), correlation=FALSE, show.resids=FALSE, ranef.comp = c(&quot;Variance&quot;)) short_summary(lmer(y ~ environment + (1+environment|animal),data)) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ environment + (1 + environment | animal) ## Data: data ## ## REML criterion at convergence: 15028.3 ## ## Random effects: ## Groups Name Variance Corr ## animal (Intercept) 0.9701 ## environment 0.4891 0.42 ## Residual 0.4960 ## Number of obs: 5200, groups: animal, 1040 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) -0.03107 0.03243 -0.958 ## environment 0.36240 0.02504 14.473 "],["4.5-indirect-genetic-effects.html", "4.5 Indirect Genetic Effects", " 4.5 Indirect Genetic Effects Indirect genetic effects are a bit more difficult to code. Lets take the example of maternal genetic effects. The maternal genetic effect that affects an individual’s phenotype, is that of its mother, not itself. Here we can use [] to index the levels of the random effects within the formula. This means that we can simulate the direct genetic and maternal genetic effects that an individual has (and the covariance between them), as well as generating an individual’s phenotype from its own direct genetic effects, and its mother’s maternal genetic effect. squid_data &lt;- simulate_population( parameters=list( animal = list( names=c(&quot;direct&quot;,&quot;maternal&quot;), vcov = matrix(c(1,0.3,0.3,0.5),2,2) ), residual = list( names=&quot;residual&quot;, vcov = 0.5 ) ), data_structure=BTped, pedigree=list(animal=BTped), model = &quot;y = direct + maternal[dam] + residual&quot; ) data &lt;- get_population_data(squid_data) head(data) ## y direct maternal residual animal dam sire squid_pop ## R187557 NA 1.0057121 0.47221848 -0.8189544 R187557 &lt;NA&gt; &lt;NA&gt; 1 ## R187559 NA -0.8595959 -1.01711203 -0.1827230 R187559 &lt;NA&gt; &lt;NA&gt; 1 ## R187568 NA 1.1343718 0.00253274 1.3185354 R187568 &lt;NA&gt; &lt;NA&gt; 1 ## R187518 NA -1.3268493 -0.93606626 -0.7956225 R187518 &lt;NA&gt; &lt;NA&gt; 1 ## R187528 NA -0.1990065 -0.38247668 0.6363527 R187528 &lt;NA&gt; &lt;NA&gt; 1 ## R187945 NA 0.8554560 0.97020718 -0.1085491 R187945 &lt;NA&gt; &lt;NA&gt; 1 "],["4.6-dominance.html", "4.6 Dominance", " 4.6 Dominance Coming soon… "],["4.7-inbreeding-depression.html", "4.7 Inbreeding depression", " 4.7 Inbreeding depression Coming soon… "],["4.8-genetic-groups.html", "4.8 Genetic Groups", " 4.8 Genetic Groups Coming soon… "],["5-phylogenetic.html", "5 Phylogenetic Effects ", " 5 Phylogenetic Effects "],["5.1-brownian-motion.html", "5.1 Brownian motion", " 5.1 Brownian motion library(ape) data(bird.families) squid_dat &lt;- simulate_population( data_structure=data.frame(taxon=bird.families$tip.label), parameters=list( taxon=list( vcov=1 ), residual=list( vcov=1 ) ), phylogeny=list(taxon=bird.families) ) pop_dat &lt;- get_population_data(squid_dat) var(pop_dat$taxon_effect) ## [1] 0.8017967 library(MCMCglmm) Ainv&lt;-inverseA(bird.families)$Ainv prior&lt;-list( R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002))) model2&lt;-MCMCglmm(y~1, random=~taxon, ginverse=list(taxon=Ainv), data=pop_dat, prior=prior, verbose=FALSE, nitt=13000, burnin=3000, thin=10) summary(model2) ## ## Iterations = 3001:12991 ## Thinning interval = 10 ## Sample size = 1000 ## ## DIC: 168.1167 ## ## G-structure: ~taxon ## ## post.mean l-95% CI u-95% CI eff.samp ## taxon 1.643 0.1346 2.938 23.95 ## ## R-structure: ~units ## ## post.mean l-95% CI u-95% CI eff.samp ## units 0.5758 0.0007948 1.4 28.69 ## ## Location effects: y ~ 1 ## ## post.mean l-95% CI u-95% CI eff.samp pMCMC ## (Intercept) 0.2780 -0.5114 1.0552 1000 0.458 "],["5.2-ornsteinuhlenbeck-process.html", "5.2 Ornstein–Uhlenbeck Process", " 5.2 Ornstein–Uhlenbeck Process Coming Soon :D "],["6-temporal-and-spatial-effects.html", "6 Temporal and Spatial Effects ", " 6 Temporal and Spatial Effects "],["6.1-simple-temporal-effects.html", "6.1 Simple Temporal Effects", " 6.1 Simple Temporal Effects We might have measured a variable over the course of a certain time period (e.g. 20 years). We might expect that there is stochastic year-to-year variation, which we can simulate already. However we might also want to simulate patterns in that temporal data. We can treat the levels associated with a particular grouping factor (e.g. year) as both a factor and continuous. To treat a grouping factor as continuous, we use covariate=TRUE in the parameter list. In this way we can simulate a linear effect of year: squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;year(20) + sex(2)/individual(50)&quot;,repeat_obs=20), parameters=list( year_cont = list( group=&quot;year&quot;, names= &quot;year_cont&quot;, covariate=TRUE, beta=0.3 ), year = list( vcov = 0.8 ), residual=list( vcov = 1 ) ) ) note we have specified group in the parameter list. This enables us to link a set of parameters to the grouping factor in the data structure. This doesn’t have to be specified and defaults to the name of the list item. data &lt;- get_population_data(squid_data) head(data) ## y year_cont year_effect residual year sex individual squid_pop ## 1 1.8129692 1 1.715485 -0.2025162 1 1 1 1 ## 2 0.8407636 1 1.715485 -1.1747219 1 1 1 1 ## 3 0.6603346 1 1.715485 -1.3551508 1 1 1 1 ## 4 2.2919631 1 1.715485 0.2764777 1 1 1 1 ## 5 2.3573981 1 1.715485 0.3419127 1 1 1 1 ## 6 1.0391202 1 1.715485 -0.9763652 1 1 1 1 plot(y ~ year_cont, data) Here we can see there is within year variation, year to year variation, as well as a linear directional year effect. lmer(y ~ year_cont + (1|year), data) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ year_cont + (1 | year) ## Data: data ## REML criterion at convergence: 113790.7 ## Random effects: ## Groups Name Std.Dev. ## year (Intercept) 0.9352 ## Residual 1.0015 ## Number of obs: 40000, groups: year, 20 ## Fixed Effects: ## (Intercept) year_cont ## 0.1705 0.3114 In a similar way we can also simulate a quadratic effect of time. squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;year(20) + sex(2)/individual(50)&quot;,repeat_obs=20), parameters=list( year_cont = list( group=&quot;year&quot;, names= c(&quot;year_cont&quot;), covariate=TRUE, beta=c(0.3) ), interactions=list( names= c(&quot;year_cont:year_cont&quot;), beta=c(-0.05) ), year = list( vcov = 1 ), residual=list( vcov = 0.8 ) ) ) data &lt;- get_population_data(squid_data) plot(y~year_cont,data) "],["6.2-cyclical-temporal-effects.html", "6.2 Cyclical Temporal Effects", " 6.2 Cyclical Temporal Effects squidR uses the sinusoidal equation to implement cyclical temporal effects \\[ y = A sin(B(x - C)) + D \\] where A is the amplitude, \\(B/2\\pi\\) is the period \\(C/B\\) is the horizontal shift and D is the vertical shift. We can visualise this time &lt;- 1:20 amplitude &lt;- 10 # |A| = the amplitude period &lt;- 10 h_shift &lt;- 3 v_shift &lt;- 5 B &lt;- (2*pi) / abs(period) # 2pi/|B| = the period cyclic_effect &lt;- amplitude*sin(B*time - B^2*h_shift ) + v_shift plot(cyclic_effect~time) We can include this complexity into the model part of the simulate_population, adding the extra parameters for the cyclical effects into the year_cont part of the list. squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;year(20) + sex(2)/individual(50)&quot;,repeat_obs=1), parameters=list( year_cont = list( group=&quot;year&quot;, names= &quot;linear_effect&quot;, covariate=TRUE, beta=0.3, amplitude = 2, # |A| = the amplitude period = 10, h_shift = 3, v_shift = 5 ), year = list( vcov = 1.2 ), residual=list( vcov = 1 ) ), model=&quot; B =(2*pi) / abs(period); cyclic_effect = amplitude*sin(B*I(linear_effect) - B^2*h_shift ) + v_shift; y = linear_effect + cyclic_effect + year_effect + residual&quot; ) data &lt;- get_population_data(squid_data) plot(y~year,data) "],["6.3-temporalauto.html", "6.3 Temporal Autocorrelation", " 6.3 Temporal Autocorrelation "],["6.4-spatialauto.html", "6.4 Spatial Autocorrelation", " 6.4 Spatial Autocorrelation "],["7-sampling.html", "7 Sampling", " 7 Sampling To create different sampling schemes, we can use the sample arguments in the simulate_population() function, for example: sample_type = &quot;nested&quot;, sample_param = cbind(individual=c(10, 15),observation=c(10, 5)), There are three different types of sampling ‘nested’, ‘missing’ and ‘temporal’, each of which are outlined below. The sample arguments create different datasets for each population that has been simulated, and you can then use the function get_sample_data() to extract the sampled data. "],["7.1-nested.html", "7.1 Nested", " 7.1 Nested Nested sampling assumes that you have a nested structure, and allows you to sample different numbers at each hierarchical level. The param input is a matrix with (named) columns. The rows of this matrix represent different sampling sets. This is most easily put together using the cbind() (column bind) function, specifying the names. The number of repeat observations for a higher level can be specified using name ‘observation’ (this doesn’t have to exist in the data structure). For example cbind(individual=c(10, 15),observation=c(10, 5)) ## individual observation ## [1,] 10 10 ## [2,] 15 5 would represent sampling the data structure above, the first set having 10 individuals each with 10 observations Note this sampling procedure only produces balanced sampling designs. For unbalanced designs see ‘missing data’ below. 7.1.1 Worked example 1 We want to see how the number of repeat measurements on individuals affects power. In order to vary the number of observations of an individual, we could specify: param &lt;- cbind(nest=10,individual=10,observation=c(20, 10, 5, 2)) pop_data &lt;- simulate_population( data_structure = make_structure(&quot;nest(10)/individual(20)&quot;,repeat_obs=20), parameters = list( individual = list( vcov = 0.1 ), observation= list( names = c(&quot;environment&quot;), beta =c(0.5) ), residual = list( vcov = 0.8 ) ), sample_type = &quot;nested&quot;, sample_param = param ) To extract the sampled data we can then use get_sample_data() specifying which sample set we want, for example the second set 10 nests, each with 10 individuals with 10 observations: sample_data &lt;- get_sample_data(pop_data, sample_set=2) length(unique(sample_data$nest)) ## [1] 10 length(unique(sample_data$individual)) ## [1] 100 nrow(sample_data) ## [1] 1000 "],["7.2-missing-data.html", "7.2 Missing data", " 7.2 Missing data The missing data methods allows generation of unbalanced data. Missing data is generated through creating probabilities of being sampled using logistic regression. Missingness can then either be random, or a function of any of the simulated variables. This methods allows the different classes of missing data to be generated: Missing Completely At Random (MCAR) All observations have an equal probability of being sampled Missing At Random (MAR) Probability of missingness is dependent on variables correlated with the response variable (i.e. a predictor variable) Missing Not At Random (MNAR) Probability of missingness is dependent on the response variable itself 7.2.1 MCAR Missing completely at random occurs when the probability of missingness is not dependent on anything. This can be implemented through a logistic regression, where only the intercept is specified: \\[ logit(p) = beta_0 \\] Note this intercept is on the logit scale, so 0 is equivalent to 0.5. pop_data &lt;- simulate_population( data_structure = make_structure(&quot;individual(100)&quot;,repeat_obs=5), parameters = list( individual = list( vcov = 0.1 ), observation= list( names = c(&quot;environment&quot;), beta =c(0.5) ), residual = list( vcov = 0.8 ) ), sample_type = &quot;missing&quot;, sample_param = &quot;0&quot; ) sample_data &lt;- get_sample_data(pop_data) nrow(sample_data) ## [1] 276 7.2.2 MAR Missing at random occurs when the probability of missingness is dependent on a predictor variable (or a variables correlated with y). This can be implemented through a logistic regression, where the predictor variable(s) is a predictor(s) of y: \\[ logit(p) = beta_0 + beta_1*environment \\] pop_data &lt;- simulate_population( data_structure = make_structure(&quot;individual(100)&quot;,repeat_obs=5), parameters = list( individual = list( vcov = 0.1 ), observation= list( names = c(&quot;environment&quot;), beta =c(0.5) ), residual = list( vcov = 0.8 ) ), sample_type = &quot;missing&quot;, sample_param = &quot;0.5*environment&quot; ) sample_data &lt;- get_sample_data(pop_data) nrow(sample_data) ## [1] 247 The predictor variables are scaled (mean 0, variance 1), so the slopes are directly comparable across traits, and intercept represents the mean (on the logit scale). 7.2.3 MNAR Missing not at random occurs when the probability of missingness is dependent on the response variable itself variable (i.e. y). This can be implemented through a logistic regression, where the predictor variable is y: \\[ logit(p) = beta_0 + beta_1*y \\] Again y is scaled. pop_data &lt;- simulate_population( data_structure = make_structure(&quot;individual(100)&quot;,repeat_obs=5), parameters = list( individual = list( vcov = 0.8 ), observation= list( names = c(&quot;environment&quot;), beta =c(0.1) ), residual = list( vcov = 0.5 ) ), sample_type = &quot;missing&quot;, sample_param = &quot;0.5*y&quot; ) sample_data &lt;- get_sample_data(pop_data) nrow(sample_data) ## [1] 274 Lets try and visualise this. We know there is lots f between individual variation, and we know sampling is based on phenotype, so we would expect an association between number of observations and phenotype: ind_data &lt;- data.frame( n=as.vector(table(sample_data$individual)), mean=tapply(sample_data$y,sample_data$individual,mean) ) boxplot(mean~n,ind_data) "],["7.3-temporal-sampling.html", "7.3 Temporal Sampling", " 7.3 Temporal Sampling In the parameters we specify a list, with the temporal variable time, the grouping variable with which the temporal sampling occurs group, the between group variance (as a proportion) in sampling times variance and the within group sample size n: pop_data &lt;- simulate_population( data_structure = make_structure(&quot;day(100) + individual(100)&quot;,repeat_obs=1), parameters = list( individual = list( vcov = 0.1 ), day=list( covariate=TRUE, beta=0.4 ), residual = list( vcov = 0.8 ) ), sample_type = &quot;temporal&quot;, sample_param = list( time = c(&quot;day&quot;), group = c(&quot;individual&quot;), variance = c(0.1,0.2), n=4), ) sample_data &lt;- get_sample_data(pop_data) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
